{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SITH-pytorch-something-something.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0h-RSfB7lA"
      },
      "source": [
        "Baseline model reference: https://github.com/TwentyBN/something-something-v2-baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwsyM3NRiNc9",
        "outputId": "a8bf046a-e89d-4e48-b6bc-cc42591f0ac8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ACX1gyuozmIF",
        "outputId": "df982e92-1828-4f20-8bca-755b81866219"
      },
      "source": [
        "%pwd\n",
        "%cd /content/gdrive/MyDrive/something-something/\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/something-something\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/something-something'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaT817Df0u8g"
      },
      "source": [
        "#%ls | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlsJwen1s5i"
      },
      "source": [
        "#Unzip something-something-v2 dataset\n",
        "#!cat 20bn-something-something-v2-?? | tar zx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYw6woCk15eX",
        "outputId": "b02cf7b4-d70c-469e-e927-8e2b6094a1df"
      },
      "source": [
        "!pip install av"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.7/dist-packages (8.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8enlh82dcEg"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import importlib\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import signal\n",
        "import time\n",
        "#import torch.utils.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD4MxMhS1oYN"
      },
      "source": [
        "sys.path.insert(0, '/content/gdrive/MyDrive/something-something/code/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zpbQtS5hZDI"
      },
      "source": [
        "from data_parser import WebmDataset\n",
        "from data_loader_av import VideoFolder\n",
        "\n",
        "from models.multi_column import MultiColumn\n",
        "from transforms_video import *\n",
        "from grad_cam_videos import GradCam\n",
        "from callbacks import (PlotLearning, AverageMeter)\n",
        "\n",
        "from utils import *\n",
        "from pprint import pprint\n",
        "\n",
        "from math import factorial\n",
        "from torch.nn.utils import weight_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIq80MJaik4g"
      },
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKMWUoKaO1-v"
      },
      "source": [
        "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJxFiJuL2DfL"
      },
      "source": [
        "config = {\n",
        "    \"model_name\": \"model_sith\",\n",
        "    \"output_dir\": \"trained_models/\",\n",
        "\n",
        "    \"input_mode\": \"av\",\n",
        "\n",
        "    \"data_folder\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/20bn-something-something-v2/\",\n",
        "\n",
        "    \"json_data_train\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-train.json\",\n",
        "    \"json_data_val\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-validation.json\",\n",
        "    \"json_data_test\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-test.json\",\n",
        "\n",
        "    \"json_file_labels\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-labels.json\",\n",
        "\n",
        "    \"num_workers\": 0,\n",
        "\n",
        "    \"num_classes\": 174,\n",
        "    \"batch_size\": 10,\n",
        "    \"clip_size\": 60,\n",
        "    \n",
        "    \"nclips_train\": 1,\n",
        "    \"nclips_val\": 1,\n",
        "\n",
        "    \"upscale_factor_train\": 1.4,\n",
        "    \"upscale_factor_eval\": 1.0,\n",
        "\n",
        "    \"step_size_train\": 1,\n",
        "    \"step_size_val\": 1,\n",
        "\n",
        "    \"lr\": 0.008,\n",
        "    \"last_lr\": 0.00001,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 0.00001,\n",
        "    \"num_epochs\": 1,\n",
        "    \"print_freq\": 100,\n",
        "\n",
        "    \"conv_model\": \"models.model3D_1\",\n",
        "    \"input_spatial_size\": 64,\n",
        "\n",
        "    \"column_units\": 512,\n",
        "    \"save_features\": True,\n",
        "    \n",
        "    \"mode\" : 'train',\n",
        "    \"start_epoch\" : 0\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmP2nn4PR4VB"
      },
      "source": [
        "sith_params1 = {\"in_features\":123008, \n",
        "                \"tau_min\":1, \"tau_max\":20.0, 'buff_max':40,\n",
        "                \"k\":50,\n",
        "                \"ntau\":5, 'g':0,  \n",
        "                \"ttype\":ttype, \n",
        "                \"hidden_size\":10, \"act_func\":nn.ReLU()}\n",
        "sith_params2 = {\"in_features\":sith_params1['hidden_size'], \n",
        "                \"tau_min\":1, \"tau_max\":200.0,  'buff_max':240,\n",
        "                \"k\":50,\n",
        "                \"ntau\":5, 'g':0, \n",
        "                \"ttype\":ttype, \n",
        "                \"hidden_size\":20, \"act_func\":nn.ReLU()}\n",
        "layer_params = [sith_params1, sith_params2]\n",
        "dropout=.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bgLJnXv2Fji"
      },
      "source": [
        "class MultiColumn(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, conv_column, column_units,\n",
        "                 clf_layers=None):\n",
        "        \"\"\"\n",
        "        - Example multi-column network\n",
        "        - Useful when a video sample is too long and has to be split into\n",
        "          multiple clips\n",
        "        - Processes 3D-CNN on each clip and averages resulting features across\n",
        "          clips before passing it to classification(FC) layer\n",
        "\n",
        "        Args:\n",
        "        - Input: Takes in a list of tensors each of size\n",
        "                 (batch_size, 3, sequence_length, W, H)\n",
        "        - Returns: logits of size (batch size, num_classes)\n",
        "        \"\"\"\n",
        "        super(MultiColumn, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.column_units = column_units\n",
        "        self.conv_column = conv_column(layer_params,dropout)\n",
        "        self.clf_layers = clf_layers\n",
        "\n",
        "        if not self.clf_layers:\n",
        "            self.clf_layers = torch.nn.Sequential(\n",
        "                                 nn.Linear(column_units, self.num_classes)\n",
        "                                )\n",
        "\n",
        "    def forward(self, inputs, get_features=False):\n",
        "        outputs = []\n",
        "        num_cols = len(inputs)\n",
        "\n",
        "        for idx in range(num_cols):\n",
        "            x = inputs[idx]\n",
        "            x = x.permute(0, 2, 1, 3, 4)\n",
        "            x1 = self.conv_column(x)\n",
        "            outputs.append(x1)\n",
        "\n",
        "        outputs = torch.stack(outputs).permute(1, 0, 2)\n",
        "        outputs = torch.squeeze(torch.sum(outputs, 1), 1)\n",
        "        avg_output = outputs / float(num_cols)\n",
        "        outputs = self.clf_layers(avg_output)\n",
        "        if get_features:\n",
        "            return outputs, avg_output\n",
        "        else:\n",
        "            return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBhDJpsGQ8Hm"
      },
      "source": [
        "# Impulse-based SITH class\n",
        "class iSITH(torch.nn.Module):\n",
        "    def __init__(self, tau_min=.1, tau_max=100., buff_max=None, k=50, ntau=50, dt=1, g=0.0,\n",
        "                 ttype=torch.FloatTensor):\n",
        "        super(iSITH, self).__init__()\n",
        "        \"\"\"A SITH module using the perfect equation for the resulting ftilde\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        \n",
        "            - tau_min: float\n",
        "                The center of the temporal receptive field for the first taustar produced. \n",
        "            - tau_max: float\n",
        "                The center of the temporal receptive field for the last taustar produced. \n",
        "            - buff_max: int\n",
        "                The maximum time in which the filters go into the past. NOTE: In order to \n",
        "                achieve as few edge effects as possible, buff_max needs to be bigger than\n",
        "                tau_max, and dependent on k, such that the filters have enough time to reach \n",
        "                very close to 0.0. Plot the filters and you will see them go to 0. \n",
        "            - k: int\n",
        "                Temporal Specificity of the taustars. If this number is high, then taustars\n",
        "                will always be more narrow.\n",
        "            - ntau: int\n",
        "                Number of taustars produced, spread out logarithmically.\n",
        "            - dt: float\n",
        "                The time delta of the model. The there will be int(buff_max/dt) filters per\n",
        "                taustar. Essentially this is the base rate of information being presented to the model\n",
        "            - g: float\n",
        "                Typically between 0 and 1. This parameter is the scaling factor of the output\n",
        "                of the module. If set to 1, the output amplitude for a delta function will be\n",
        "                identical through time. If set to 0, the amplitude will decay into the past, \n",
        "                getting smaller and smaller. This value should be picked on an application to \n",
        "                application basis.\n",
        "            - ttype: Torch Tensor\n",
        "                This is the type we set the internal mechanism of the model to before running. \n",
        "                In order to calculate the filters, we must use a DoubleTensor, but this is no \n",
        "                longer necessary after they are calculated. By default we set the filters to \n",
        "                be FloatTensors. NOTE: If you plan to use CUDA, you need to pass in a \n",
        "                cuda.FloatTensor as the ttype, as using .cuda() will not put these filters on \n",
        "                the gpu. \n",
        "            \n",
        "                \n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.tau_min = tau_min\n",
        "        self.tau_max = tau_max\n",
        "        if buff_max is None:\n",
        "            buff_max = 3*tau_max\n",
        "        self.buff_max = buff_max\n",
        "        self.ntau = ntau\n",
        "        self.dt = dt\n",
        "        self.g = g\n",
        "        \n",
        "        self.c = (tau_max/tau_min)**(1./(ntau-1))-1\n",
        "        \n",
        "        self.tau_star = tau_min*(1+self.c)**torch.arange(ntau).type(torch.DoubleTensor)\n",
        "        \n",
        "        self.times = torch.arange(dt, buff_max+dt, dt).type(torch.DoubleTensor)\n",
        "        \n",
        "        A = ((1/self.tau_star)*(k**(k+1)/factorial(k))*(self.tau_star**self.g)).unsqueeze(1)\n",
        "        self.filters = A*((self.times.unsqueeze(0)/self.tau_star.unsqueeze(1))**(k+1)) * \\\n",
        "                        torch.exp(k*(-self.times.unsqueeze(0)/self.tau_star.unsqueeze(1)))\n",
        "        self.filters = torch.flip(self.filters, [-1]).unsqueeze(1).unsqueeze(1)\n",
        "        self.filters = self.filters.type(ttype)\n",
        "    \n",
        "    def extra_repr(self):\n",
        "        s = \"ntau={ntau}, tau_min={tau_min}, tau_max={tau_max}, buff_max={buff_max}, dt={dt}, k={k}, g={g}\"\n",
        "        s = s.format(**self.__dict__)\n",
        "        return s    \n",
        "    \n",
        "    def forward(self, inp):\n",
        "        \"\"\"Takes in (Batch, 1, features, sequence) and returns (Batch, Taustar, features, sequence)\"\"\"\n",
        "        assert(len(inp.shape) >= 4)        \n",
        "        out = torch.conv2d(inp, self.filters[:, :, :, -inp.shape[-1]:], \n",
        "                           padding=[0, self.filters[:, :, :, -inp.shape[-1]:].shape[-1]])\n",
        "                           #padding=[0, self.filters.shape[-1]])\n",
        "        # note we're scaling the output by both dt and the k/(k+1)\n",
        "        # Off by 1 introduced by the conv2d\n",
        "        return out[:, :, :, 1:inp.shape[-1]+1]*self.dt*self.k/(self.k+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRB1dR7SQ9Th"
      },
      "source": [
        "class _DeepSITH_core(nn.Module):\n",
        "    def __init__(self, layer_params):\n",
        "        super(_DeepSITH_core, self).__init__()\n",
        "\n",
        "        hidden_size = layer_params.pop('hidden_size', layer_params['in_features'])\n",
        "        in_features = layer_params.pop('in_features', None)\n",
        "        act_func = layer_params.pop('act_func', None)\n",
        "\n",
        "        self.sith = iSITH(**layer_params)\n",
        "\n",
        "        if act_func is None:\n",
        "            self.linear = weight_norm(nn.Linear(layer_params['ntau']*in_features,\n",
        "                                                hidden_size))\n",
        "            nn.init.kaiming_normal_(self.linear.weight.data)  \n",
        "        else:\n",
        "            self.linear = nn.Sequential(weight_norm(nn.Linear(layer_params['ntau']*in_features,\n",
        "                                                hidden_size)),\n",
        "                                        act_func)\n",
        "            nn.init.kaiming_normal_(self.linear[0].weight.data)  \n",
        "    \n",
        "    def forward(self, inp):\n",
        "        x = self.sith(inp)\n",
        "        x = x.transpose(3,2).transpose(2,1)\n",
        "        x = x.view(x.shape[0], x.shape[1], -1)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DeepSITH(nn.Module):\n",
        "    \"\"\"A Module built for SITH like an LSTM\n",
        "    Parameters\n",
        "    ----------\n",
        "    layer_params: list\n",
        "        A list of dictionaries for each layer in the desired DeepSITH. All\n",
        "        of the parameters needed for the SITH part of the Layers, as well as\n",
        "        a hidden_size and optional act_func are required to be present.\n",
        "    layer_params keys\n",
        "    -----------------\n",
        "    hidden_size: int (default in_features)\n",
        "        The size of the output of the hidden layer. Please note that the\n",
        "        in_features parameter for the next layer's SITH representation should be\n",
        "        equal to the previous layer's hidden_size. This parameter will default\n",
        "        to the in_features of the current SITH layer if not specified.\n",
        "    act_func: torch.nn.Module (default None)\n",
        "        The torch layer of the desired activation function, or None if no\n",
        "        there is no desired activation function between layers.\n",
        "    In addition to these keys, you must include all of the non-optional SITH\n",
        "    layer keys in each dictionary. Please see the SITH docstring for\n",
        "    suggestions.\n",
        "    \"\"\"\n",
        "    def __init__(self, layer_params, dropout=.5):\n",
        "        super(DeepSITH, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(nn.Conv2d(in_channels=3,\n",
        "                              out_channels=32, kernel_size=(3,3)),\n",
        "                              nn.Flatten())\n",
        "        \n",
        "        self.layers = nn.ModuleList([_DeepSITH_core(layer_params[i])\n",
        "                                      for i in range(len(layer_params))])\n",
        "        self.dropouts = nn.ModuleList([nn.Dropout(dropout) for i in range(len(layer_params) - 1)])\n",
        "\n",
        "        self.decoder = nn.Sequential(nn.Linear(20, 1024),\n",
        "                                     nn.Unflatten(2, (32, 32)))\n",
        "        \n",
        "        self.decoder_conv3d = nn.Conv3d(in_channels=1,\n",
        "                                     out_channels=512,\n",
        "                                     kernel_size=(3, 3, 3),\n",
        "                                     padding=(0, 1, 1))\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        x = inp\n",
        "\n",
        "        encoded = []\n",
        "        for t in range(x.shape[1]):\n",
        "            encoded += [self.encoder(x[:,t,:,:,:])]\n",
        "        \n",
        "        encoded_stacked = torch.stack(encoded, 1)\n",
        "\n",
        "        encoded_stacked.unsqueeze_(1)\n",
        "\n",
        "        encoded_stacked = encoded_stacked.permute(0,1,3,2)\n",
        "\n",
        "        for i, l in enumerate(self.layers[:-1]):\n",
        "            x = l(encoded_stacked)\n",
        "            x = self.dropouts[i](x)\n",
        "            x = x.unsqueeze(1).transpose(3,2)\n",
        "        x = self.layers[-1](x)\n",
        "\n",
        "        outputs = self.decoder(x)\n",
        "        outputs.unsqueeze_(1)\n",
        "        outputs = self.decoder_conv3d(outputs)\n",
        "        outputs = torch.nn.Sigmoid()(outputs)\n",
        "        outputs = outputs.mean(-1).mean(-1).mean(-1)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0cx8TOs2YMq",
        "outputId": "0821766b-a9e6-4386-8257-bf70be416ea0"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device_ids = []\n",
        "if device.type == \"cuda\":\n",
        "    # How many GPUs are there?\n",
        "    print(torch.cuda.device_count())\n",
        "    device_ids = [torch.cuda.current_device()]\n",
        "print(device, device_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "cuda [0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-EM3slG2awH",
        "outputId": "2be41ea0-b4f4-48b6-e6ed-fbd7cb6c7ffa"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 25 04:59:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iT3ci972ele",
        "outputId": "e536d496-906b-4943-8d85-1eab24591fd7"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CR8l9F_2hrH"
      },
      "source": [
        "global best_loss\n",
        "best_loss = float('Inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRMRQH4R2lbe"
      },
      "source": [
        "if config[\"input_mode\"] == \"av\":\n",
        "    from data_loader_av import VideoFolder\n",
        "elif config[\"input_mode\"] == \"skvideo\":\n",
        "    from data_loader_skvideo import VideoFolder\n",
        "else:\n",
        "    raise ValueError(\"Please provide a valid input mode\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnjW4NXj2n2F",
        "outputId": "bcbf1ce2-2bfd-4fdc-c10c-c478bbbad220"
      },
      "source": [
        "# set run output folder\n",
        "model_name = config[\"model_name\"]\n",
        "output_dir = config[\"output_dir\"]\n",
        "save_dir = os.path.join(output_dir, model_name)\n",
        "print(\" > Output folder for this run -- {}\".format(save_dir))\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "    os.makedirs(os.path.join(save_dir, 'plots'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Output folder for this run -- trained_models/model3D_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WszO1Jmk8OAH",
        "outputId": "0fbdaecb-eeb6-45b1-b274-e8b3c3443124"
      },
      "source": [
        "%cd /content/\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9tZsMeI6pui",
        "outputId": "22542da2-77bd-4b55-c485-7f287855cbdf"
      },
      "source": [
        "# create model\n",
        "print(\" > Creating model ... !\")\n",
        "model = MultiColumn(config['num_classes'], DeepSITH,\n",
        "                        int(config[\"column_units\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Creating model ... !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB4yHdED6vTI"
      },
      "source": [
        "# multi GPU setting\n",
        "model = torch.nn.DataParallel(model, device_ids).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vNnHfhD6xoI"
      },
      "source": [
        "# optionally resume from a checkpoint\n",
        "checkpoint_path = os.path.join(config['output_dir'],\n",
        "                                   config['model_name'],\n",
        "                                   'model_best.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDPxAVLY6z9P"
      },
      "source": [
        "if config['mode'] is 'resume':\n",
        "    if os.path.isfile(checkpoint_path):\n",
        "        print(\" > Loading checkpoint '{}'\".format(args.resume))\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        args.start_epoch = checkpoint['epoch']\n",
        "        best_loss = checkpoint['best_loss']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        print(\" > Loaded checkpoint '{}' (epoch {})\"\n",
        "              .format(checkpoint_path, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\" !#! No checkpoint found at '{}'\".format(\n",
        "            checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVLGVbSZ62PP"
      },
      "source": [
        "# define augmentation pipeline\n",
        "upscale_size_train = int(config['input_spatial_size'] * config[\"upscale_factor_train\"])\n",
        "upscale_size_eval = int(config['input_spatial_size'] * config[\"upscale_factor_eval\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wgDMUGI64se"
      },
      "source": [
        "# Random crop videos during training\n",
        "transform_train_pre = ComposeMix([\n",
        "        [RandomRotationVideo(15), \"vid\"],\n",
        "        [Scale(upscale_size_train), \"img\"],\n",
        "        [RandomCropVideo(config['input_spatial_size']), \"vid\"],\n",
        "         ])\n",
        "\n",
        "# Center crop videos during evaluation\n",
        "transform_eval_pre = ComposeMix([\n",
        "        [Scale(upscale_size_eval), \"img\"],\n",
        "        [torchvision.transforms.ToPILImage(), \"img\"],\n",
        "        [torchvision.transforms.CenterCrop(config['input_spatial_size']), \"img\"],\n",
        "         ])\n",
        "\n",
        "# Transforms common to train and eval sets and applied after \"pre\" transforms\n",
        "transform_post = ComposeMix([\n",
        "        [torchvision.transforms.ToTensor(), \"img\"],\n",
        "        [torchvision.transforms.Normalize(\n",
        "                   mean=[0.485, 0.456, 0.406],  # default values for imagenet\n",
        "                   std=[0.229, 0.224, 0.225]), \"img\"]\n",
        "         ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjtSWQb_662N"
      },
      "source": [
        "train_data = VideoFolder(root=config['data_folder'],\n",
        "                             json_file_input=config['json_data_train'],\n",
        "                             json_file_labels=config['json_file_labels'],\n",
        "                             clip_size=config['clip_size'],\n",
        "                             nclips=config['nclips_train'],\n",
        "                             step_size=config['step_size_train'],\n",
        "                             is_val=False,\n",
        "                             transform_pre=transform_train_pre,\n",
        "                             transform_post=transform_post,\n",
        "                             #augmentation_mappings_json=config['augmentation_mappings_json'],\n",
        "                             #augmentation_types_todo=config['augmentation_types_todo'],\n",
        "                             get_item_id=False,\n",
        "                             )\n",
        "\n",
        "print(len(train_data))\n",
        "train_data = Subset(train_data, np.arange(10000))\n",
        "print(train_data.dataset.classes)\n",
        "print(len(train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XR7oTGK69Dv",
        "outputId": "e497726d-a658-4e4c-de4f-69bc5b1c38c4"
      },
      "source": [
        "print(\" > Using {} processes for data loader.\".format(\n",
        "        config[\"num_workers\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Using 0 processes for data loader.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IzSg_NCfgn8"
      },
      "source": [
        "#def my_collate(batch):\n",
        "#    \"Puts each data field into a tensor with outer dimension batch size\"\n",
        "#    batch = filter (lambda x:x is not None, batch)\n",
        "#    return torch.utils.data.dataloader.default_collate(list(batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fquRsh26_0u"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_data,\n",
        "        batch_size=config['batch_size'], shuffle=False,\n",
        "        num_workers=config['num_workers'], pin_memory=True,\n",
        "        drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d224DRal7C-1"
      },
      "source": [
        "val_data = VideoFolder(root=config['data_folder'],\n",
        "                           json_file_input=config['json_data_val'],\n",
        "                           json_file_labels=config['json_file_labels'],\n",
        "                           clip_size=config['clip_size'],\n",
        "                           nclips=config['nclips_val'],\n",
        "                           step_size=config['step_size_val'],\n",
        "                           is_val=True,\n",
        "                           transform_pre=transform_eval_pre,\n",
        "                           transform_post=transform_post,\n",
        "                           get_item_id=True,\n",
        "                           )\n",
        "\n",
        "val_data = Subset(val_data, np.arange(100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzjT-S5o7FH9"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "        val_data,\n",
        "        batch_size=config['batch_size'], shuffle=False,\n",
        "        num_workers=config['num_workers'], pin_memory=True,\n",
        "        drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbupYtON7Hbc"
      },
      "source": [
        "test_data = VideoFolder(root=config['data_folder'],\n",
        "                            json_file_input=config['json_data_test'],\n",
        "                            json_file_labels=config['json_file_labels'],\n",
        "                            clip_size=config['clip_size'],\n",
        "                            nclips=config['nclips_val'],\n",
        "                            step_size=config['step_size_val'],\n",
        "                            is_val=True,\n",
        "                            transform_pre=transform_eval_pre,\n",
        "                            transform_post=transform_post,\n",
        "                            get_item_id=True,\n",
        "                            is_test=True,\n",
        "                            )\n",
        "\n",
        "test_data = Subset(test_data, np.arange(100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAhn1zNp7JV1"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "        test_data,\n",
        "        batch_size=config['batch_size'], shuffle=False,\n",
        "        num_workers=config['num_workers'], pin_memory=True,\n",
        "        drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kb90Pfq7LK0",
        "outputId": "4eec59c9-d216-459f-f1dd-be921dac54ed"
      },
      "source": [
        "print(\" > Number of dataset classes : {}\".format(len(train_data.dataset.classes)))\n",
        "assert len(train_data.dataset.classes) == config[\"num_classes\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Number of dataset classes : 174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSbAwAY7M8M"
      },
      "source": [
        "# define loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK40sjYj7Of0"
      },
      "source": [
        "# define optimizer\n",
        "lr = config[\"lr\"]\n",
        "last_lr = config[\"last_lr\"]\n",
        "momentum = config['momentum']\n",
        "weight_decay = config['weight_decay']\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
        "                            momentum=momentum,\n",
        "                            weight_decay=weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmr34F0x7QId"
      },
      "source": [
        "# **************************Only Validate***********************\n",
        "if config[\"mode\"] == \"validate\":\n",
        "        validate(test_loader, model, criterion, train_data.dataset.classes_dict)\n",
        "        print(\" > Evaluation DONE !\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHTosHz27USa"
      },
      "source": [
        "# set callbacks\n",
        "plotter = PlotLearning(os.path.join(\n",
        "    save_dir, \"plots\"), config[\"num_classes\"])\n",
        "lr_decayer = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                    optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
        "val_loss = float('Inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7NF8GjY7V4T"
      },
      "source": [
        "# set end condition by num epochs\n",
        "num_epochs = int(config[\"num_epochs\"])\n",
        "if num_epochs == -1:\n",
        "    num_epochs = 999999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg-dXnnK7XgK",
        "outputId": "b41c68a6-00b6-42ae-ff93-63505eec07e1"
      },
      "source": [
        "print(\" > Training is getting started...\")\n",
        "print(\" > Training takes {} epochs.\".format(num_epochs))\n",
        "start_epoch = config[\"start_epoch\"] #args.start_epoch if args.resume else 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Training is getting started...\n",
            " > Training takes 1 epochs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0u3xkh97Z37"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if config['nclips_train'] > 1:\n",
        "            input_var = list(input.split(config['clip_size'], 2))\n",
        "            for idx, inp in enumerate(input_var):\n",
        "                input_var[idx] = inp.to(device)\n",
        "        else:\n",
        "            input_var = [input.to(device)]\n",
        "\n",
        "        target = target.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # compute output and loss\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(output.detach().cpu(), target.detach().cpu(), topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "        top5.update(prec5.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % config[\"print_freq\"] == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
        "    return losses.avg, top1.avg, top5.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P9YRnJy7dQp"
      },
      "source": [
        "def validate(val_loader, model, criterion, class_to_idx=None):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    logits_matrix = []\n",
        "    features_matrix = []\n",
        "    targets_list = []\n",
        "    item_id_list = []\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target, item_id) in enumerate(val_loader):\n",
        "\n",
        "            if config['nclips_val'] > 1:\n",
        "                input_var = list(input.split(config['clip_size'], 2))\n",
        "                for idx, inp in enumerate(input_var):\n",
        "                    input_var[idx] = inp.to(device)\n",
        "            else:\n",
        "                input_var = [input.to(device)]\n",
        "\n",
        "            target = target.to(device)\n",
        "\n",
        "            # compute output and loss\n",
        "            output, features = model(input_var, config['save_features'])\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            if config[\"mode\"] == 'validate':\n",
        "                logits_matrix.append(output.cpu().data.numpy())\n",
        "                features_matrix.append(features.cpu().data.numpy())\n",
        "                targets_list.append(target.cpu().numpy())\n",
        "                item_id_list.append(item_id)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1, prec5 = accuracy(output.detach().cpu(), target.detach().cpu(), topk=(1, 5))\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1.item(), input.size(0))\n",
        "            top5.update(prec5.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % config[\"print_freq\"] == 0:\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                          i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                          top1=top1, top5=top5))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
        "          .format(top1=top1, top5=top5))\n",
        "\n",
        "    if config[\"mode\"] == 'validate':\n",
        "        logits_matrix = np.concatenate(logits_matrix)\n",
        "        features_matrix = np.concatenate(features_matrix)\n",
        "        targets_list = np.concatenate(targets_list)\n",
        "        item_id_list = np.concatenate(item_id_list)\n",
        "        print(logits_matrix.shape, targets_list.shape, item_id_list.shape)\n",
        "        save_results(logits_matrix, features_matrix, targets_list,\n",
        "                     item_id_list, class_to_idx, config)\n",
        "        get_submission(logits_matrix, item_id_list, class_to_idx, config)\n",
        "    return losses.avg, top1.avg, top5.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WJg-ywQ7fv5",
        "outputId": "e3d350ae-c13b-460d-e4eb-1328e3cd00a9"
      },
      "source": [
        "for epoch in range(start_epoch, num_epochs):\n",
        "\n",
        "    lrs = [params['lr'] for params in optimizer.param_groups]\n",
        "    print(\" > Current LR(s) -- {}\".format(lrs))\n",
        "    if np.max(lr) < last_lr and last_lr > 0:\n",
        "        print(\" > Training is DONE by learning rate {}\".format(last_lr))\n",
        "        break\n",
        "\n",
        "    # train for one epoch\n",
        "    train_loss, train_top1, train_top5 = train(\n",
        "        train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    val_loss, val_top1, val_top5 = validate(val_loader, model, criterion)\n",
        "\n",
        "    # set learning rate\n",
        "    lr_decayer.step(val_loss, epoch)\n",
        "\n",
        "    # plot learning\n",
        "    plotter_dict = {}\n",
        "    plotter_dict['loss'] = train_loss\n",
        "    plotter_dict['val_loss'] = val_loss\n",
        "    plotter_dict['acc'] = train_top1 / 100\n",
        "    plotter_dict['val_acc'] = val_top1 / 100\n",
        "    plotter_dict['learning_rate'] = lr\n",
        "    plotter.plot(plotter_dict)\n",
        "\n",
        "    print(\" > Validation loss after epoch {} = {}\".format(epoch, val_loss))\n",
        "\n",
        "    # remember best loss and save the checkpoint\n",
        "    is_best = val_loss < best_loss\n",
        "    best_loss = min(val_loss, best_loss)\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'arch': \"Conv4Col\",\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_loss': best_loss,\n",
        "    }, is_best, config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Current LR(s) -- [0.008]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/something-something/code/data_loader_av.py:56: AttributeRenamedWarning: VideoFrame.to_nd_array is deprecated; please use VideoFrame.to_ndarray.\n",
            "  imgs = [f.to_rgb().to_nd_array() for f in reader.decode(video=0)]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Epoch: [0][0/16891]\tTime 1.587 (1.587)\tData 1.345 (1.345)\tLoss 5.2510 (5.2510)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n",
            "Train loop: input var size:1\n",
            "Train loop: input size:torch.Size([10, 3, 60, 64, 64])\n",
            "Train loop: target size:torch.Size([10])\n",
            "0. Initial Input list size:1\n",
            "1. Initial Input size:torch.Size([10, 3, 60, 64, 64])\n",
            "2. Number of columns:1\n",
            "3. Inputs size before permute:torch.Size([10, 3, 60, 64, 64])\n",
            "3. Inputs size after permute:torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 inp: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH x1 x: torch.Size([10, 60, 3, 64, 64])\n",
            "DeepSITH encoded seq size: 60\n",
            "DeepSITH encoded seq size stacked: torch.Size([10, 60, 123008])\n",
            "DeepSITH encoded seq size unsqueezed: torch.Size([10, 1, 60, 123008])\n",
            "DeepSITH encoded seq size permuted: torch.Size([10, 1, 123008, 60])\n",
            "Enumerate: 0\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 123008, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 123008])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 615040])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 10])\n",
            "DeepSITH x2: torch.Size([10, 60, 10])\n",
            "DeepSITH x3: torch.Size([10, 60, 10])\n",
            "DeepSITH x4: torch.Size([10, 1, 10, 60])\n",
            "***\n",
            "DeepSITHCORE x1: torch.Size([10, 5, 10, 60])\n",
            "DeepSITHCORE x2: torch.Size([10, 60, 5, 10])\n",
            "DeepSITHCORE x3: torch.Size([10, 60, 50])\n",
            "DeepSITHCORE x4: torch.Size([10, 60, 20])\n",
            "DeepSITH x5: torch.Size([10, 60, 20])\n",
            "DeepSITH x6: torch.Size([10, 60, 32, 32])\n",
            "DeepSITH x7: torch.Size([10, 1, 60, 32, 32])\n",
            "DeepSITH x8: torch.Size([10, 512, 58, 32, 32])\n",
            "DeepSITH x9: torch.Size([10, 512])\n",
            "4. x1 size:torch.Size([10, 512])\n",
            "5. outputs len:1\n",
            "6. outputs size after stack/permute:torch.Size([10, 1, 512])\n",
            "7. outputs size after squeeze:torch.Size([10, 512])\n",
            "8. avg output size:torch.Size([10, 512])\n",
            "9. outputs size after clf_layers:torch.Size([10, 174])\n",
            "Train loop: Output size:torch.Size([10, 174])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqu_ervs_Pb0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}