{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convlstm-pytorch-something-something.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Yy2_M6B2At"
      },
      "source": [
        "Baseline model reference: https://github.com/TwentyBN/something-something-v2-baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwsyM3NRiNc9",
        "outputId": "b05bc8b1-aca1-44e4-d349-476af197277e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ACX1gyuozmIF",
        "outputId": "454a1c16-a451-4406-b2ea-a360ebf30ece"
      },
      "source": [
        "%pwd\n",
        "%cd /content/gdrive/MyDrive/something-something/\n",
        "%pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/something-something\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/something-something'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaT817Df0u8g"
      },
      "source": [
        "#%ls | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlsJwen1s5i"
      },
      "source": [
        "#Unzip something-something-v2 dataset\n",
        "#!cat 20bn-something-something-v2-?? | tar zx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYw6woCk15eX",
        "outputId": "5b3ecd0c-8429-405f-df85-09472468c20d"
      },
      "source": [
        "!pip install av"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.7/dist-packages (8.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8enlh82dcEg"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import importlib\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import signal\n",
        "import time\n",
        "#import torch.utils.data\n",
        "from torch.utils.data.dataset import Subset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD4MxMhS1oYN"
      },
      "source": [
        "sys.path.insert(0, '/content/gdrive/MyDrive/something-something/code/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zpbQtS5hZDI"
      },
      "source": [
        "from data_parser import WebmDataset\n",
        "from data_loader_av import VideoFolder\n",
        "\n",
        "from models.multi_column import MultiColumn\n",
        "from transforms_video import *\n",
        "from grad_cam_videos import GradCam\n",
        "from callbacks import (PlotLearning, AverageMeter)\n",
        "\n",
        "from utils import *\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIq80MJaik4g"
      },
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJxFiJuL2DfL"
      },
      "source": [
        "config = {\n",
        "    \"model_name\": \"model_convlstm\",\n",
        "    \"output_dir\": \"/content/gdrive/MyDrive/something-something/trained_models/\",\n",
        "\n",
        "    \"input_mode\": \"av\",\n",
        "\n",
        "    \"data_folder\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/20bn-something-something-v2/\",\n",
        "\n",
        "    \"json_data_train\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-train.json\",\n",
        "    \"json_data_val\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-validation.json\",\n",
        "    \"json_data_test\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-test.json\",\n",
        "\n",
        "    \"json_file_labels\": \"/content/gdrive/MyDrive/something-something/something-something-dataset/annotations/something-something-v2-labels.json\",\n",
        "\n",
        "    \"num_workers\": 0,\n",
        "\n",
        "    \"num_classes\": 174,\n",
        "    \"batch_size\": 10,\n",
        "    \"clip_size\": 60,\n",
        "    \n",
        "    \"nclips_train\": 1,\n",
        "    \"nclips_val\": 1,\n",
        "\n",
        "    \"upscale_factor_train\": 1.4,\n",
        "    \"upscale_factor_eval\": 1.0,\n",
        "\n",
        "    \"step_size_train\": 1,\n",
        "    \"step_size_val\": 1,\n",
        "\n",
        "    \"lr\": 0.008,\n",
        "    \"last_lr\": 0.00001,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 0.00001,\n",
        "    \"num_epochs\": 100,\n",
        "    \"print_freq\": 100,\n",
        "\n",
        "    \"conv_model\": \"models.model3D_1\",\n",
        "    \"input_spatial_size\": 64,\n",
        "\n",
        "    \"column_units\": 512,\n",
        "    \"save_features\": True,\n",
        "    \n",
        "    \"mode\" : 'train',\n",
        "    \"start_epoch\" : 0\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bgLJnXv2Fji"
      },
      "source": [
        "class MultiColumn(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, conv_column, column_units,\n",
        "                 clf_layers=None):\n",
        "        \"\"\"\n",
        "        - Example multi-column network\n",
        "        - Useful when a video sample is too long and has to be split into\n",
        "          multiple clips\n",
        "        - Processes 3D-CNN on each clip and averages resulting features across\n",
        "          clips before passing it to classification(FC) layer\n",
        "\n",
        "        Args:\n",
        "        - Input: Takes in a list of tensors each of size\n",
        "                 (batch_size, 3, sequence_length, W, H)\n",
        "        - Returns: logits of size (batch size, num_classes)\n",
        "        \"\"\"\n",
        "        super(MultiColumn, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.column_units = column_units\n",
        "        self.conv_column = conv_column(64,3)\n",
        "        self.clf_layers = clf_layers\n",
        "\n",
        "        if not self.clf_layers:\n",
        "            self.clf_layers = torch.nn.Sequential(\n",
        "                                 nn.Linear(column_units, self.num_classes)\n",
        "                                )\n",
        "\n",
        "    def forward(self, inputs, get_features=False):\n",
        "        outputs = []\n",
        "        num_cols = len(inputs)\n",
        "\n",
        "        for idx in range(num_cols):\n",
        "            x = inputs[idx]\n",
        "            x = x.permute(0, 2, 1, 3, 4)\n",
        "            x1 = self.conv_column(x)\n",
        "            outputs.append(x1)\n",
        "\n",
        "        outputs = torch.stack(outputs).permute(1, 0, 2)\n",
        "        outputs = torch.squeeze(torch.sum(outputs, 1), 1)\n",
        "        avg_output = outputs / float(num_cols)\n",
        "        outputs = self.clf_layers(avg_output)\n",
        "        if get_features:\n",
        "            return outputs, avg_output\n",
        "        else:\n",
        "            return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc1wsjuqC_Wa"
      },
      "source": [
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
        "        \"\"\"\n",
        "        Initialize ConvLSTM cell.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim: int\n",
        "            Number of channels of input tensor.\n",
        "        hidden_dim: int\n",
        "            Number of channels of hidden state.\n",
        "        kernel_size: (int, int)\n",
        "            Size of the convolutional kernel.\n",
        "        bias: bool\n",
        "            Whether or not to add the bias.\n",
        "        \"\"\"\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "        self.bias = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_hidden(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
        "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOj9_kcXFoLK"
      },
      "source": [
        "class EncoderDecoderConvLSTM(nn.Module):\n",
        "    def __init__(self, nf, in_chan):\n",
        "        super(EncoderDecoderConvLSTM, self).__init__()\n",
        "\n",
        "        \"\"\" ARCHITECTURE \n",
        "\n",
        "        # Encoder (ConvLSTM)\n",
        "        # Encoder Vector (final hidden state of encoder)\n",
        "        # Decoder (ConvLSTM) - takes Encoder Vector as input\n",
        "        # Decoder (3D CNN) - produces regression predictions for our model\n",
        "\n",
        "        \"\"\"\n",
        "        self.encoder_1_convlstm = ConvLSTMCell(input_dim=in_chan,\n",
        "                                               hidden_dim=nf,\n",
        "                                               kernel_size=(3, 3),\n",
        "                                               bias=True)\n",
        "\n",
        "        self.encoder_2_convlstm = ConvLSTMCell(input_dim=nf,\n",
        "                                               hidden_dim=nf,\n",
        "                                               kernel_size=(3, 3),\n",
        "                                               bias=True)\n",
        "\n",
        "        self.decoder_1_convlstm = ConvLSTMCell(input_dim=nf,  # nf + 1\n",
        "                                               hidden_dim=nf,\n",
        "                                               kernel_size=(3, 3),\n",
        "                                               bias=True)\n",
        "\n",
        "        self.decoder_2_convlstm = ConvLSTMCell(input_dim=nf,\n",
        "                                               hidden_dim=nf,\n",
        "                                               kernel_size=(3, 3),\n",
        "                                               bias=True)\n",
        "\n",
        "        self.decoder_CNN = nn.Conv3d(in_channels=nf,\n",
        "                                     out_channels=512,\n",
        "                                     kernel_size=(3, 3, 3),\n",
        "                                     padding=(1, 1, 1))\n",
        "\n",
        "\n",
        "    def autoencoder(self, x, seq_len, future_step, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4):\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        # encoder\n",
        "        for t in range(seq_len):\n",
        "            h_t, c_t = self.encoder_1_convlstm(input_tensor=x[:, t, :, :, :],\n",
        "                                               cur_state=[h_t, c_t])  # we could concat to provide skip conn here\n",
        "            h_t2, c_t2 = self.encoder_2_convlstm(input_tensor=h_t,\n",
        "                                                 cur_state=[h_t2, c_t2])  # we could concat to provide skip conn here\n",
        "        # encoder_vector\n",
        "        encoder_vector = h_t2\n",
        "\n",
        "        # decoder\n",
        "        for t in range(future_step):\n",
        "            h_t3, c_t3 = self.decoder_1_convlstm(input_tensor=encoder_vector,\n",
        "                                                 cur_state=[h_t3, c_t3])  # we could concat to provide skip conn here\n",
        "            h_t4, c_t4 = self.decoder_2_convlstm(input_tensor=h_t3,\n",
        "                                                 cur_state=[h_t4, c_t4])  # we could concat to provide skip conn here\n",
        "            encoder_vector = h_t4\n",
        "            outputs += [h_t4]  # predictions\n",
        "        outputs = torch.stack(outputs, 1)\n",
        "        outputs = outputs.permute(0, 2, 1, 3, 4)\n",
        "        outputs = self.decoder_CNN(outputs)\n",
        "        outputs = outputs.mean(-1).mean(-1).mean(-1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def forward(self, x, future_seq=10, hidden_state=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor:\n",
        "            5-D Tensor of shape (b, t, c, h, w)        #   batch, time, channel, height, width\n",
        "        \"\"\"\n",
        "\n",
        "        # find size of different input dimensions\n",
        "        b, seq_len, _, h, w = x.size()\n",
        "\n",
        "        # initialize hidden states\n",
        "        h_t, c_t = self.encoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "        h_t2, c_t2 = self.encoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "        h_t3, c_t3 = self.decoder_1_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "        h_t4, c_t4 = self.decoder_2_convlstm.init_hidden(batch_size=b, image_size=(h, w))\n",
        "\n",
        "        # autoencoder forward\n",
        "        outputs = self.autoencoder(x, seq_len, future_seq, h_t, c_t, h_t2, c_t2, h_t3, c_t3, h_t4, c_t4)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0cx8TOs2YMq",
        "outputId": "871692de-b2d8-40ca-9337-15f37cf6013c"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device_ids = []\n",
        "if device.type == \"cuda\":\n",
        "    # How many GPUs are there?\n",
        "    print(torch.cuda.device_count())\n",
        "    device_ids = [torch.cuda.current_device()]\n",
        "print(device, device_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "cuda [0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-EM3slG2awH",
        "outputId": "d551668e-2d46-4100-9141-21f24ba48c9d"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 26 04:22:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iT3ci972ele",
        "outputId": "09cedb7e-674f-4d50-fcdd-73ab140e707a"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CR8l9F_2hrH"
      },
      "source": [
        "global best_loss\n",
        "best_loss = float('Inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRMRQH4R2lbe"
      },
      "source": [
        "if config[\"input_mode\"] == \"av\":\n",
        "    from data_loader_av import VideoFolder\n",
        "elif config[\"input_mode\"] == \"skvideo\":\n",
        "    from data_loader_skvideo import VideoFolder\n",
        "else:\n",
        "    raise ValueError(\"Please provide a valid input mode\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnjW4NXj2n2F",
        "outputId": "b5dbbb9b-9ee8-4df7-cd55-2690e4725658"
      },
      "source": [
        "# set run output folder\n",
        "model_name = config[\"model_name\"]\n",
        "output_dir = config[\"output_dir\"]\n",
        "save_dir = os.path.join(output_dir, model_name)\n",
        "print(\" > Output folder for this run -- {}\".format(save_dir))\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "    os.makedirs(os.path.join(save_dir, 'plots'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Output folder for this run -- /content/gdrive/MyDrive/something-something/trained_models/model_convlstm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WszO1Jmk8OAH",
        "outputId": "525b0039-28c6-4422-9e16-f5376740165a"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/something-something/\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/something-something\n",
            "20bn-something-something-v2-00  20bn-something-something-v2-12\n",
            "20bn-something-something-v2-01  20bn-something-something-v2-13\n",
            "20bn-something-something-v2-02  20bn-something-something-v2-14\n",
            "20bn-something-something-v2-03  20bn-something-something-v2-15\n",
            "20bn-something-something-v2-04  20bn-something-something-v2-16\n",
            "20bn-something-something-v2-05  20bn-something-something-v2-17\n",
            "20bn-something-something-v2-06  20bn-something-something-v2-18\n",
            "20bn-something-something-v2-07  20bn-something-something-v2-19\n",
            "20bn-something-something-v2-08  \u001b[0m\u001b[01;34mcode\u001b[0m/\n",
            "20bn-something-something-v2-09  \u001b[01;34msomething-something-dataset\u001b[0m/\n",
            "20bn-something-something-v2-10  \u001b[01;34mtrained_models\u001b[0m/\n",
            "20bn-something-something-v2-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9tZsMeI6pui",
        "outputId": "c6340f58-2b10-43c7-b66c-74b9968761bc"
      },
      "source": [
        "# create model\n",
        "print(\" > Creating model ... !\")\n",
        "model = MultiColumn(config['num_classes'], EncoderDecoderConvLSTM,\n",
        "                        int(config[\"column_units\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Creating model ... !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB4yHdED6vTI"
      },
      "source": [
        "# multi GPU setting\n",
        "model = torch.nn.DataParallel(model, device_ids).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vNnHfhD6xoI"
      },
      "source": [
        "# optionally resume from a checkpoint\n",
        "checkpoint_path = os.path.join(config['output_dir'],\n",
        "                                   config['model_name'],\n",
        "                                   'model_best.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDPxAVLY6z9P"
      },
      "source": [
        "if config['mode'] is 'resume':\n",
        "    if os.path.isfile(checkpoint_path):\n",
        "        print(\" > Loading checkpoint '{}'\".format(args.resume))\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        args.start_epoch = checkpoint['epoch']\n",
        "        best_loss = checkpoint['best_loss']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        print(\" > Loaded checkpoint '{}' (epoch {})\"\n",
        "              .format(checkpoint_path, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\" !#! No checkpoint found at '{}'\".format(\n",
        "            checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVLGVbSZ62PP"
      },
      "source": [
        "# define augmentation pipeline\n",
        "upscale_size_train = int(config['input_spatial_size'] * config[\"upscale_factor_train\"])\n",
        "upscale_size_eval = int(config['input_spatial_size'] * config[\"upscale_factor_eval\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wgDMUGI64se"
      },
      "source": [
        "# Random crop videos during training\n",
        "transform_train_pre = ComposeMix([\n",
        "        [RandomRotationVideo(15), \"vid\"],\n",
        "        [Scale(upscale_size_train), \"img\"],\n",
        "        [RandomCropVideo(config['input_spatial_size']), \"vid\"],\n",
        "         ])\n",
        "\n",
        "# Center crop videos during evaluation\n",
        "transform_eval_pre = ComposeMix([\n",
        "        [Scale(upscale_size_eval), \"img\"],\n",
        "        [torchvision.transforms.ToPILImage(), \"img\"],\n",
        "        [torchvision.transforms.CenterCrop(config['input_spatial_size']), \"img\"],\n",
        "         ])\n",
        "\n",
        "# Transforms common to train and eval sets and applied after \"pre\" transforms\n",
        "transform_post = ComposeMix([\n",
        "        [torchvision.transforms.ToTensor(), \"img\"],\n",
        "        [torchvision.transforms.Normalize(\n",
        "                   mean=[0.485, 0.456, 0.406],  # default values for imagenet\n",
        "                   std=[0.229, 0.224, 0.225]), \"img\"]\n",
        "         ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjtSWQb_662N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9483ee4d-78d2-4802-b41d-aa663c9cf810"
      },
      "source": [
        "train_data = VideoFolder(root=config['data_folder'],\n",
        "                             json_file_input=config['json_data_train'],\n",
        "                             json_file_labels=config['json_file_labels'],\n",
        "                             clip_size=config['clip_size'],\n",
        "                             nclips=config['nclips_train'],\n",
        "                             step_size=config['step_size_train'],\n",
        "                             is_val=False,\n",
        "                             transform_pre=transform_train_pre,\n",
        "                             transform_post=transform_post,\n",
        "                             #augmentation_mappings_json=config['augmentation_mappings_json'],\n",
        "                             #augmentation_types_todo=config['augmentation_types_todo'],\n",
        "                             get_item_id=False,\n",
        "                             )\n",
        "print(len(train_data))\n",
        "train_data = Subset(train_data, np.arange(20000))\n",
        "print(train_data.dataset.classes)\n",
        "print(len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "168913\n",
            "['Approaching something with your camera', 'Attaching something to something', 'Bending something so that it deforms', 'Bending something until it breaks', 'Burying something in something', 'Closing something', 'Covering something with something', 'Digging something out of something', 'Dropping something behind something', 'Dropping something in front of something', 'Dropping something into something', 'Dropping something next to something', 'Dropping something onto something', 'Failing to put something into something because something does not fit', 'Folding something', 'Hitting something with something', 'Holding something', 'Holding something behind something', 'Holding something in front of something', 'Holding something next to something', 'Holding something over something', 'Laying something on the table on its side, not upright', 'Letting something roll along a flat surface', 'Letting something roll down a slanted surface', 'Letting something roll up a slanted surface, so it rolls back down', 'Lifting a surface with something on it but not enough for it to slide down', 'Lifting a surface with something on it until it starts sliding down', 'Lifting something up completely without letting it drop down', 'Lifting something up completely, then letting it drop down', 'Lifting something with something on it', 'Lifting up one end of something without letting it drop down', 'Lifting up one end of something, then letting it drop down', 'Moving away from something with your camera', 'Moving part of something', 'Moving something across a surface until it falls down', 'Moving something across a surface without it falling down', 'Moving something and something away from each other', 'Moving something and something closer to each other', 'Moving something and something so they collide with each other', 'Moving something and something so they pass each other', 'Moving something away from something', 'Moving something away from the camera', 'Moving something closer to something', 'Moving something down', 'Moving something towards the camera', 'Moving something up', 'Opening something', 'Picking something up', 'Piling something up', 'Plugging something into something', 'Plugging something into something but pulling it right out as you remove your hand', 'Poking a hole into some substance', 'Poking a hole into something soft', 'Poking a stack of something so the stack collapses', 'Poking a stack of something without the stack collapsing', 'Poking something so it slightly moves', \"Poking something so lightly that it doesn't or almost doesn't move\", 'Poking something so that it falls over', 'Poking something so that it spins around', 'Pouring something into something', 'Pouring something into something until it overflows', 'Pouring something onto something', 'Pouring something out of something', 'Pretending or failing to wipe something off of something', 'Pretending or trying and failing to twist something', 'Pretending to be tearing something that is not tearable', 'Pretending to close something without actually closing it', 'Pretending to open something without actually opening it', 'Pretending to pick something up', 'Pretending to poke something', 'Pretending to pour something out of something, but something is empty', 'Pretending to put something behind something', 'Pretending to put something into something', 'Pretending to put something next to something', 'Pretending to put something on a surface', 'Pretending to put something onto something', 'Pretending to put something underneath something', 'Pretending to scoop something up with something', 'Pretending to spread air onto something', 'Pretending to sprinkle air onto something', 'Pretending to squeeze something', 'Pretending to take something from somewhere', 'Pretending to take something out of something', 'Pretending to throw something', 'Pretending to turn something upside down', 'Pulling something from behind of something', 'Pulling something from left to right', 'Pulling something from right to left', 'Pulling something onto something', 'Pulling something out of something', 'Pulling two ends of something but nothing happens', 'Pulling two ends of something so that it gets stretched', 'Pulling two ends of something so that it separates into two pieces', 'Pushing something from left to right', 'Pushing something from right to left', 'Pushing something off of something', 'Pushing something onto something', 'Pushing something so it spins', \"Pushing something so that it almost falls off but doesn't\", 'Pushing something so that it falls off the table', 'Pushing something so that it slightly moves', 'Pushing something with something', 'Putting number of something onto something', 'Putting something and something on the table', 'Putting something behind something', 'Putting something in front of something', 'Putting something into something', 'Putting something next to something', 'Putting something on a flat surface without letting it roll', 'Putting something on a surface', 'Putting something on the edge of something so it is not supported and falls down', \"Putting something onto a slanted surface but it doesn't glide down\", 'Putting something onto something', 'Putting something onto something else that cannot support it so it falls down', 'Putting something similar to other things that are already on the table', \"Putting something that can't roll onto a slanted surface, so it slides down\", \"Putting something that can't roll onto a slanted surface, so it stays where it is\", 'Putting something that cannot actually stand upright upright on the table, so it falls on its side', 'Putting something underneath something', 'Putting something upright on the table', 'Putting something, something and something on the table', 'Removing something, revealing something behind', 'Rolling something on a flat surface', 'Scooping something up with something', 'Showing a photo of something to the camera', 'Showing something behind something', 'Showing something next to something', 'Showing something on top of something', 'Showing something to the camera', 'Showing that something is empty', 'Showing that something is inside something', 'Something being deflected from something', 'Something colliding with something and both are being deflected', 'Something colliding with something and both come to a halt', 'Something falling like a feather or paper', 'Something falling like a rock', 'Spilling something behind something', 'Spilling something next to something', 'Spilling something onto something', 'Spinning something so it continues spinning', 'Spinning something that quickly stops spinning', 'Spreading something onto something', 'Sprinkling something onto something', 'Squeezing something', 'Stacking number of something', 'Stuffing something into something', 'Taking one of many similar things on the table', 'Taking something from somewhere', 'Taking something out of something', 'Tearing something into two pieces', 'Tearing something just a little bit', 'Throwing something', 'Throwing something against something', 'Throwing something in the air and catching it', 'Throwing something in the air and letting it fall', 'Throwing something onto a surface', \"Tilting something with something on it slightly so it doesn't fall down\", 'Tilting something with something on it until it falls off', 'Tipping something over', 'Tipping something with something in it over, so something in it falls out', 'Touching (without moving) part of something', \"Trying but failing to attach something to something because it doesn't stick\", 'Trying to bend something unbendable so nothing happens', 'Trying to pour something into something, but missing so it spills next to it', 'Turning something upside down', 'Turning the camera downwards while filming something', 'Turning the camera left while filming something', 'Turning the camera right while filming something', 'Turning the camera upwards while filming something', 'Twisting (wringing) something wet until water comes out', 'Twisting something', 'Uncovering something', 'Unfolding something', 'Wiping something off of something']\n",
            "20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XR7oTGK69Dv",
        "outputId": "8629181f-2d85-421a-ddac-100f29c5632f"
      },
      "source": [
        "print(\" > Using {} processes for data loader.\".format(\n",
        "        config[\"num_workers\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Using 0 processes for data loader.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IzSg_NCfgn8"
      },
      "source": [
        "#def my_collate(batch):\n",
        "#    \"Puts each data field into a tensor with outer dimension batch size\"\n",
        "#    batch = filter (lambda x:x is not None, batch)\n",
        "#    return torch.utils.data.dataloader.default_collate(list(batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fquRsh26_0u"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        train_data,\n",
        "        batch_size=config['batch_size'], shuffle=False,\n",
        "        num_workers=config['num_workers'], pin_memory=True,\n",
        "        drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d224DRal7C-1"
      },
      "source": [
        "val_data = VideoFolder(root=config['data_folder'],\n",
        "                           json_file_input=config['json_data_val'],\n",
        "                           json_file_labels=config['json_file_labels'],\n",
        "                           clip_size=config['clip_size'],\n",
        "                           nclips=config['nclips_val'],\n",
        "                           step_size=config['step_size_val'],\n",
        "                           is_val=True,\n",
        "                           transform_pre=transform_eval_pre,\n",
        "                           transform_post=transform_post,\n",
        "                           get_item_id=True,\n",
        "                           )\n",
        "val_data = Subset(val_data, np.arange(1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzjT-S5o7FH9"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "        val_data,\n",
        "        batch_size=config['batch_size'], shuffle=False,\n",
        "        num_workers=config['num_workers'], pin_memory=True,\n",
        "        drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbupYtON7Hbc"
      },
      "source": [
        "test_data = VideoFolder(root=config['data_folder'],\n",
        "                            json_file_input=config['json_data_test'],\n",
        "                            json_file_labels=config['json_file_labels'],\n",
        "                            clip_size=config['clip_size'],\n",
        "                            nclips=config['nclips_val'],\n",
        "                            step_size=config['step_size_val'],\n",
        "                            is_val=True,\n",
        "                            transform_pre=transform_eval_pre,\n",
        "                            transform_post=transform_post,\n",
        "                            get_item_id=True,\n",
        "                            is_test=True,\n",
        "                            )\n",
        "test_data = Subset(test_data, np.arange(1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAhn1zNp7JV1"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "        test_data,\n",
        "        batch_size=config['batch_size'], shuffle=False,\n",
        "        num_workers=config['num_workers'], pin_memory=True,\n",
        "        drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kb90Pfq7LK0",
        "outputId": "b95ca4da-d4a3-42d2-8304-01baa1885c87"
      },
      "source": [
        "print(\" > Number of dataset classes : {}\".format(len(train_data.dataset.classes)))\n",
        "assert len(train_data.dataset.classes) == config[\"num_classes\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Number of dataset classes : 174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSbAwAY7M8M"
      },
      "source": [
        "# define loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK40sjYj7Of0"
      },
      "source": [
        "# define optimizer\n",
        "lr = config[\"lr\"]\n",
        "last_lr = config[\"last_lr\"]\n",
        "momentum = config['momentum']\n",
        "weight_decay = config['weight_decay']\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
        "                            momentum=momentum,\n",
        "                            weight_decay=weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmr34F0x7QId"
      },
      "source": [
        "# **************************Only Validate***********************\n",
        "if config[\"mode\"] == \"validate\":\n",
        "        validate(test_loader, model, criterion, train_data.dataset.classes_dict)\n",
        "        print(\" > Evaluation DONE !\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHTosHz27USa"
      },
      "source": [
        "# set callbacks\n",
        "plotter = PlotLearning(os.path.join(\n",
        "    save_dir, \"plots\"), config[\"num_classes\"])\n",
        "lr_decayer = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                    optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
        "val_loss = float('Inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7NF8GjY7V4T"
      },
      "source": [
        "# set end condition by num epochs\n",
        "num_epochs = int(config[\"num_epochs\"])\n",
        "if num_epochs == -1:\n",
        "    num_epochs = 999999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg-dXnnK7XgK",
        "outputId": "80f1b9a1-b5c8-4da0-f318-5e3a1ae90bc0"
      },
      "source": [
        "print(\" > Training is getting started...\")\n",
        "print(\" > Training takes {} epochs.\".format(num_epochs))\n",
        "start_epoch = config[\"start_epoch\"] #args.start_epoch if args.resume else 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Training is getting started...\n",
            " > Training takes 100 epochs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0u3xkh97Z37"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if config['nclips_train'] > 1:\n",
        "            input_var = list(input.split(config['clip_size'], 2))\n",
        "            for idx, inp in enumerate(input_var):\n",
        "                input_var[idx] = inp.to(device)\n",
        "        else:\n",
        "            input_var = [input.to(device)]\n",
        "\n",
        "        target = target.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        # compute output and loss\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(output.detach().cpu(), target.detach().cpu(), topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec1.item(), input.size(0))\n",
        "        top5.update(prec5.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % config[\"print_freq\"] == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
        "    return losses.avg, top1.avg, top5.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P9YRnJy7dQp"
      },
      "source": [
        "def validate(val_loader, model, criterion, class_to_idx=None):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    logits_matrix = []\n",
        "    features_matrix = []\n",
        "    targets_list = []\n",
        "    item_id_list = []\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target, item_id) in enumerate(val_loader):\n",
        "\n",
        "            if config['nclips_val'] > 1:\n",
        "                input_var = list(input.split(config['clip_size'], 2))\n",
        "                for idx, inp in enumerate(input_var):\n",
        "                    input_var[idx] = inp.to(device)\n",
        "            else:\n",
        "                input_var = [input.to(device)]\n",
        "\n",
        "            target = target.to(device)\n",
        "\n",
        "            # compute output and loss\n",
        "            output, features = model(input_var, config['save_features'])\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            if config[\"mode\"] == 'validate':\n",
        "                logits_matrix.append(output.cpu().data.numpy())\n",
        "                features_matrix.append(features.cpu().data.numpy())\n",
        "                targets_list.append(target.cpu().numpy())\n",
        "                item_id_list.append(item_id)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec1, prec5 = accuracy(output.detach().cpu(), target.detach().cpu(), topk=(1, 5))\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec1.item(), input.size(0))\n",
        "            top5.update(prec5.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % config[\"print_freq\"] == 0:\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
        "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
        "                          i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                          top1=top1, top5=top5))\n",
        "\n",
        "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
        "          .format(top1=top1, top5=top5))\n",
        "\n",
        "    if config[\"mode\"] == 'validate':\n",
        "        logits_matrix = np.concatenate(logits_matrix)\n",
        "        features_matrix = np.concatenate(features_matrix)\n",
        "        targets_list = np.concatenate(targets_list)\n",
        "        item_id_list = np.concatenate(item_id_list)\n",
        "        print(logits_matrix.shape, targets_list.shape, item_id_list.shape)\n",
        "        save_results(logits_matrix, features_matrix, targets_list,\n",
        "                     item_id_list, class_to_idx, config)\n",
        "        get_submission(logits_matrix, item_id_list, class_to_idx, config)\n",
        "    return losses.avg, top1.avg, top5.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WJg-ywQ7fv5",
        "outputId": "76552a14-9848-4582-8de7-e93b94de3c11"
      },
      "source": [
        "for epoch in range(start_epoch, num_epochs):\n",
        "\n",
        "    lrs = [params['lr'] for params in optimizer.param_groups]\n",
        "    print(\" > Current LR(s) -- {}\".format(lrs))\n",
        "    if np.max(lr) < last_lr and last_lr > 0:\n",
        "        print(\" > Training is DONE by learning rate {}\".format(last_lr))\n",
        "        break\n",
        "\n",
        "    # train for one epoch\n",
        "    train_loss, train_top1, train_top5 = train(\n",
        "        train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    val_loss, val_top1, val_top5 = validate(val_loader, model, criterion)\n",
        "\n",
        "    # set learning rate\n",
        "    lr_decayer.step(val_loss, epoch)\n",
        "\n",
        "    # plot learning\n",
        "    plotter_dict = {}\n",
        "    plotter_dict['loss'] = train_loss\n",
        "    plotter_dict['val_loss'] = val_loss\n",
        "    plotter_dict['acc'] = train_top1 / 100\n",
        "    plotter_dict['val_acc'] = val_top1 / 100\n",
        "    plotter_dict['learning_rate'] = lr\n",
        "    plotter.plot(plotter_dict)\n",
        "\n",
        "    print(\" > Validation loss after epoch {} = {}\".format(epoch, val_loss))\n",
        "\n",
        "    # remember best loss and save the checkpoint\n",
        "    is_best = val_loss < best_loss\n",
        "    best_loss = min(val_loss, best_loss)\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'arch': \"Conv4Col\",\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_loss': best_loss,\n",
        "    }, is_best, config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Current LR(s) -- [0.008]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/something-something/code/data_loader_av.py:56: AttributeRenamedWarning: VideoFrame.to_nd_array is deprecated; please use VideoFrame.to_ndarray.\n",
            "  imgs = [f.to_rgb().to_nd_array() for f in reader.decode(video=0)]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0][0/2000]\tTime 1.780 (1.780)\tData 1.209 (1.209)\tLoss 5.1696 (5.1696)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            "Epoch: [0][100/2000]\tTime 1.749 (1.709)\tData 1.210 (1.169)\tLoss 5.1640 (5.1470)\tPrec@1 0.000 (0.891)\tPrec@5 0.000 (5.743)\n",
            "Epoch: [0][200/2000]\tTime 1.686 (1.704)\tData 1.146 (1.164)\tLoss 5.0639 (5.1315)\tPrec@1 0.000 (1.244)\tPrec@5 10.000 (7.313)\n",
            "Epoch: [0][300/2000]\tTime 1.756 (1.705)\tData 1.216 (1.165)\tLoss 5.0399 (5.1122)\tPrec@1 10.000 (1.329)\tPrec@5 10.000 (7.542)\n",
            "Epoch: [0][400/2000]\tTime 1.629 (1.704)\tData 1.089 (1.164)\tLoss 4.8714 (5.0874)\tPrec@1 0.000 (1.372)\tPrec@5 0.000 (7.406)\n",
            "Epoch: [0][500/2000]\tTime 1.713 (1.703)\tData 1.174 (1.163)\tLoss 4.9290 (5.0704)\tPrec@1 0.000 (1.597)\tPrec@5 0.000 (7.605)\n",
            "Epoch: [0][600/2000]\tTime 1.690 (1.701)\tData 1.150 (1.161)\tLoss 4.8096 (5.0581)\tPrec@1 10.000 (1.631)\tPrec@5 20.000 (7.438)\n",
            "Epoch: [0][700/2000]\tTime 1.669 (1.700)\tData 1.129 (1.161)\tLoss 4.6283 (5.0463)\tPrec@1 10.000 (1.655)\tPrec@5 40.000 (7.532)\n",
            "Epoch: [0][800/2000]\tTime 1.707 (1.700)\tData 1.167 (1.160)\tLoss 5.0322 (5.0409)\tPrec@1 0.000 (1.598)\tPrec@5 0.000 (7.366)\n",
            "Epoch: [0][900/2000]\tTime 1.675 (1.699)\tData 1.135 (1.160)\tLoss 4.9934 (5.0334)\tPrec@1 0.000 (1.620)\tPrec@5 10.000 (7.425)\n",
            "Epoch: [0][1000/2000]\tTime 2.251 (1.699)\tData 1.712 (1.159)\tLoss 4.8413 (5.0289)\tPrec@1 0.000 (1.658)\tPrec@5 10.000 (7.542)\n",
            "Epoch: [0][1100/2000]\tTime 1.687 (1.722)\tData 1.148 (1.182)\tLoss 4.7414 (5.0259)\tPrec@1 0.000 (1.644)\tPrec@5 20.000 (7.593)\n",
            "Epoch: [0][1200/2000]\tTime 2.567 (1.742)\tData 2.027 (1.202)\tLoss 5.1495 (5.0212)\tPrec@1 0.000 (1.699)\tPrec@5 0.000 (7.619)\n",
            "Epoch: [0][1300/2000]\tTime 2.520 (1.758)\tData 1.981 (1.218)\tLoss 5.0115 (5.0202)\tPrec@1 0.000 (1.706)\tPrec@5 20.000 (7.625)\n",
            "Epoch: [0][1400/2000]\tTime 1.674 (1.769)\tData 1.134 (1.230)\tLoss 5.0175 (5.0174)\tPrec@1 20.000 (1.734)\tPrec@5 20.000 (7.630)\n",
            "Epoch: [0][1500/2000]\tTime 1.700 (1.777)\tData 1.160 (1.238)\tLoss 4.9678 (5.0174)\tPrec@1 0.000 (1.746)\tPrec@5 10.000 (7.588)\n",
            "Epoch: [0][1600/2000]\tTime 1.692 (1.787)\tData 1.153 (1.247)\tLoss 4.9526 (5.0164)\tPrec@1 0.000 (1.730)\tPrec@5 0.000 (7.589)\n",
            "Epoch: [0][1700/2000]\tTime 1.716 (1.795)\tData 1.176 (1.255)\tLoss 5.0540 (5.0145)\tPrec@1 0.000 (1.734)\tPrec@5 10.000 (7.625)\n",
            "Epoch: [0][1800/2000]\tTime 1.704 (1.801)\tData 1.164 (1.261)\tLoss 5.1118 (5.0127)\tPrec@1 0.000 (1.743)\tPrec@5 0.000 (7.762)\n",
            "Epoch: [0][1900/2000]\tTime 1.702 (1.810)\tData 1.162 (1.270)\tLoss 5.1287 (5.0083)\tPrec@1 0.000 (1.773)\tPrec@5 10.000 (7.912)\n",
            "Test: [0/100]\tTime 1.176 (1.176)\tLoss 4.9798 (4.9798)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.500 Prec@5 7.300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:628: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " > Validation loss after epoch 0 = 5.0240919876098635\n",
            " > Best model found at this epoch. Saving ...\n",
            " > Current LR(s) -- [0.008]\n",
            "Epoch: [1][0/2000]\tTime 1.738 (1.738)\tData 1.197 (1.197)\tLoss 5.0068 (5.0068)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            "Epoch: [1][100/2000]\tTime 1.718 (1.697)\tData 1.178 (1.157)\tLoss 5.1090 (4.9579)\tPrec@1 0.000 (1.980)\tPrec@5 0.000 (9.802)\n",
            "Epoch: [1][200/2000]\tTime 1.695 (1.691)\tData 1.155 (1.151)\tLoss 4.7872 (4.9660)\tPrec@1 0.000 (1.891)\tPrec@5 20.000 (9.403)\n",
            "Epoch: [1][300/2000]\tTime 1.707 (1.692)\tData 1.167 (1.152)\tLoss 4.9953 (4.9667)\tPrec@1 10.000 (1.827)\tPrec@5 10.000 (9.070)\n",
            "Epoch: [1][400/2000]\tTime 1.683 (1.691)\tData 1.143 (1.150)\tLoss 4.7932 (4.9672)\tPrec@1 0.000 (1.721)\tPrec@5 10.000 (8.703)\n",
            "Epoch: [1][500/2000]\tTime 1.696 (1.692)\tData 1.157 (1.152)\tLoss 4.8989 (4.9685)\tPrec@1 0.000 (1.836)\tPrec@5 0.000 (8.643)\n",
            "Epoch: [1][600/2000]\tTime 1.669 (1.692)\tData 1.128 (1.152)\tLoss 4.8304 (4.9684)\tPrec@1 10.000 (1.797)\tPrec@5 20.000 (8.436)\n",
            "Epoch: [1][700/2000]\tTime 1.676 (1.691)\tData 1.137 (1.151)\tLoss 4.6092 (4.9658)\tPrec@1 10.000 (1.797)\tPrec@5 40.000 (8.359)\n",
            "Epoch: [1][800/2000]\tTime 1.673 (1.691)\tData 1.133 (1.151)\tLoss 5.0370 (4.9684)\tPrec@1 0.000 (1.760)\tPrec@5 0.000 (8.215)\n",
            "Epoch: [1][900/2000]\tTime 1.676 (1.692)\tData 1.136 (1.152)\tLoss 4.9674 (4.9678)\tPrec@1 0.000 (1.754)\tPrec@5 10.000 (8.224)\n",
            "Epoch: [1][1000/2000]\tTime 1.670 (1.692)\tData 1.131 (1.152)\tLoss 4.8344 (4.9688)\tPrec@1 0.000 (1.768)\tPrec@5 10.000 (8.242)\n",
            "Epoch: [1][1100/2000]\tTime 1.810 (1.692)\tData 1.269 (1.151)\tLoss 4.7343 (4.9701)\tPrec@1 0.000 (1.753)\tPrec@5 20.000 (8.238)\n",
            "Epoch: [1][1200/2000]\tTime 1.734 (1.693)\tData 1.193 (1.153)\tLoss 5.1035 (4.9693)\tPrec@1 0.000 (1.799)\tPrec@5 0.000 (8.218)\n",
            "Epoch: [1][1300/2000]\tTime 1.657 (1.692)\tData 1.117 (1.151)\tLoss 5.0288 (4.9717)\tPrec@1 0.000 (1.799)\tPrec@5 20.000 (8.224)\n",
            "Epoch: [1][1400/2000]\tTime 1.687 (1.693)\tData 1.146 (1.153)\tLoss 4.9951 (4.9721)\tPrec@1 20.000 (1.813)\tPrec@5 20.000 (8.194)\n",
            "Epoch: [1][1500/2000]\tTime 1.720 (1.694)\tData 1.180 (1.154)\tLoss 4.9515 (4.9746)\tPrec@1 0.000 (1.819)\tPrec@5 10.000 (8.128)\n",
            "Epoch: [1][1600/2000]\tTime 1.690 (1.695)\tData 1.150 (1.155)\tLoss 4.9356 (4.9758)\tPrec@1 0.000 (1.824)\tPrec@5 0.000 (8.064)\n",
            "Epoch: [1][1700/2000]\tTime 1.709 (1.695)\tData 1.169 (1.155)\tLoss 5.0432 (4.9759)\tPrec@1 0.000 (1.817)\tPrec@5 10.000 (8.078)\n",
            "Epoch: [1][1800/2000]\tTime 1.717 (1.697)\tData 1.177 (1.157)\tLoss 5.0999 (4.9759)\tPrec@1 0.000 (1.827)\tPrec@5 0.000 (8.207)\n",
            "Epoch: [1][1900/2000]\tTime 1.764 (1.699)\tData 1.223 (1.159)\tLoss 5.1273 (4.9733)\tPrec@1 0.000 (1.862)\tPrec@5 10.000 (8.322)\n",
            "Test: [0/100]\tTime 1.225 (1.225)\tLoss 4.9754 (4.9754)\tPrec@1 10.000 (10.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.700 Prec@5 7.300\n",
            " > Validation loss after epoch 1 = 5.0229439401626585\n",
            " > Best model found at this epoch. Saving ...\n",
            " > Current LR(s) -- [0.008]\n",
            "Epoch: [2][0/2000]\tTime 1.765 (1.765)\tData 1.226 (1.226)\tLoss 4.9996 (4.9996)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            "Epoch: [2][100/2000]\tTime 1.689 (1.745)\tData 1.149 (1.206)\tLoss 5.1012 (4.9532)\tPrec@1 0.000 (1.980)\tPrec@5 0.000 (9.802)\n",
            "Epoch: [2][200/2000]\tTime 1.775 (1.742)\tData 1.236 (1.202)\tLoss 4.7831 (4.9615)\tPrec@1 0.000 (1.940)\tPrec@5 20.000 (9.602)\n",
            "Epoch: [2][300/2000]\tTime 1.705 (1.741)\tData 1.166 (1.202)\tLoss 4.9996 (4.9625)\tPrec@1 10.000 (1.894)\tPrec@5 10.000 (9.203)\n",
            "Epoch: [2][400/2000]\tTime 1.693 (1.740)\tData 1.153 (1.200)\tLoss 4.7772 (4.9631)\tPrec@1 0.000 (1.796)\tPrec@5 30.000 (8.928)\n",
            "Epoch: [2][500/2000]\tTime 1.752 (1.741)\tData 1.213 (1.201)\tLoss 4.8882 (4.9645)\tPrec@1 0.000 (1.916)\tPrec@5 0.000 (8.902)\n",
            "Epoch: [2][600/2000]\tTime 1.736 (1.740)\tData 1.197 (1.200)\tLoss 4.8329 (4.9642)\tPrec@1 10.000 (1.847)\tPrec@5 20.000 (8.652)\n",
            "Epoch: [2][700/2000]\tTime 1.697 (1.736)\tData 1.157 (1.196)\tLoss 4.6065 (4.9616)\tPrec@1 10.000 (1.840)\tPrec@5 40.000 (8.559)\n",
            "Epoch: [2][800/2000]\tTime 1.730 (1.733)\tData 1.190 (1.194)\tLoss 5.0382 (4.9643)\tPrec@1 0.000 (1.773)\tPrec@5 10.000 (8.377)\n",
            "Epoch: [2][900/2000]\tTime 1.759 (1.732)\tData 1.218 (1.192)\tLoss 4.9594 (4.9640)\tPrec@1 0.000 (1.743)\tPrec@5 10.000 (8.335)\n",
            "Epoch: [2][1000/2000]\tTime 1.760 (1.733)\tData 1.220 (1.193)\tLoss 4.8336 (4.9650)\tPrec@1 0.000 (1.758)\tPrec@5 0.000 (8.372)\n",
            "Epoch: [2][1100/2000]\tTime 1.781 (1.737)\tData 1.241 (1.197)\tLoss 4.7335 (4.9664)\tPrec@1 0.000 (1.735)\tPrec@5 20.000 (8.347)\n",
            "Epoch: [2][1200/2000]\tTime 1.798 (1.738)\tData 1.257 (1.198)\tLoss 5.0844 (4.9656)\tPrec@1 0.000 (1.782)\tPrec@5 0.000 (8.318)\n",
            "Epoch: [2][1300/2000]\tTime 1.860 (1.740)\tData 1.320 (1.200)\tLoss 5.0341 (4.9682)\tPrec@1 0.000 (1.783)\tPrec@5 20.000 (8.332)\n",
            "Epoch: [2][1400/2000]\tTime 1.747 (1.742)\tData 1.208 (1.202)\tLoss 4.9866 (4.9687)\tPrec@1 20.000 (1.799)\tPrec@5 20.000 (8.301)\n",
            "Epoch: [2][1500/2000]\tTime 1.746 (1.743)\tData 1.206 (1.204)\tLoss 4.9454 (4.9712)\tPrec@1 0.000 (1.805)\tPrec@5 10.000 (8.235)\n",
            "Epoch: [2][1600/2000]\tTime 1.792 (1.745)\tData 1.252 (1.205)\tLoss 4.9297 (4.9725)\tPrec@1 0.000 (1.811)\tPrec@5 0.000 (8.164)\n",
            "Epoch: [2][1700/2000]\tTime 1.768 (1.746)\tData 1.227 (1.207)\tLoss 5.0408 (4.9727)\tPrec@1 0.000 (1.805)\tPrec@5 10.000 (8.207)\n",
            "Epoch: [2][1800/2000]\tTime 1.777 (1.747)\tData 1.237 (1.207)\tLoss 5.0946 (4.9727)\tPrec@1 0.000 (1.866)\tPrec@5 0.000 (8.329)\n",
            "Epoch: [2][1900/2000]\tTime 1.769 (1.748)\tData 1.229 (1.208)\tLoss 5.1260 (4.9702)\tPrec@1 0.000 (1.899)\tPrec@5 10.000 (8.438)\n",
            "Test: [0/100]\tTime 1.236 (1.236)\tLoss 4.9732 (4.9732)\tPrec@1 10.000 (10.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.700 Prec@5 7.300\n",
            " > Validation loss after epoch 2 = 5.023154997825623\n",
            " > Current LR(s) -- [0.008]\n",
            "Epoch: [3][0/2000]\tTime 1.751 (1.751)\tData 1.212 (1.212)\tLoss 4.9957 (4.9957)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            "Epoch: [3][100/2000]\tTime 1.719 (1.746)\tData 1.180 (1.207)\tLoss 5.0986 (4.9511)\tPrec@1 0.000 (1.980)\tPrec@5 0.000 (9.802)\n",
            "Epoch: [3][200/2000]\tTime 1.729 (1.738)\tData 1.190 (1.199)\tLoss 4.7811 (4.9595)\tPrec@1 0.000 (1.990)\tPrec@5 20.000 (9.602)\n",
            "Epoch: [3][300/2000]\tTime 1.762 (1.742)\tData 1.223 (1.202)\tLoss 5.0019 (4.9607)\tPrec@1 10.000 (1.927)\tPrec@5 10.000 (9.203)\n",
            "Epoch: [3][400/2000]\tTime 1.695 (1.742)\tData 1.156 (1.203)\tLoss 4.7690 (4.9612)\tPrec@1 0.000 (1.820)\tPrec@5 30.000 (8.903)\n",
            "Epoch: [3][500/2000]\tTime 1.716 (1.741)\tData 1.177 (1.202)\tLoss 4.8835 (4.9627)\tPrec@1 0.000 (1.936)\tPrec@5 0.000 (8.882)\n",
            "Epoch: [3][600/2000]\tTime 1.768 (1.739)\tData 1.229 (1.200)\tLoss 4.8343 (4.9623)\tPrec@1 10.000 (1.864)\tPrec@5 30.000 (8.669)\n",
            "Epoch: [3][700/2000]\tTime 1.726 (1.737)\tData 1.187 (1.198)\tLoss 4.6056 (4.9597)\tPrec@1 10.000 (1.854)\tPrec@5 40.000 (8.588)\n",
            "Epoch: [3][800/2000]\tTime 1.733 (1.736)\tData 1.195 (1.196)\tLoss 5.0378 (4.9624)\tPrec@1 0.000 (1.773)\tPrec@5 10.000 (8.427)\n",
            "Epoch: [3][900/2000]\tTime 1.739 (1.737)\tData 1.200 (1.198)\tLoss 4.9555 (4.9621)\tPrec@1 0.000 (1.709)\tPrec@5 10.000 (8.357)\n",
            "Epoch: [3][1000/2000]\tTime 1.734 (1.737)\tData 1.195 (1.198)\tLoss 4.8336 (4.9632)\tPrec@1 0.000 (1.728)\tPrec@5 0.000 (8.392)\n",
            "Epoch: [3][1100/2000]\tTime 1.773 (1.737)\tData 1.233 (1.198)\tLoss 4.7334 (4.9646)\tPrec@1 0.000 (1.735)\tPrec@5 20.000 (8.365)\n",
            "Epoch: [3][1200/2000]\tTime 1.770 (1.738)\tData 1.231 (1.199)\tLoss 5.0737 (4.9639)\tPrec@1 0.000 (1.782)\tPrec@5 0.000 (8.326)\n",
            "Epoch: [3][1300/2000]\tTime 1.733 (1.739)\tData 1.194 (1.200)\tLoss 5.0371 (4.9665)\tPrec@1 0.000 (1.783)\tPrec@5 20.000 (8.332)\n",
            "Epoch: [3][1400/2000]\tTime 1.698 (1.738)\tData 1.159 (1.199)\tLoss 4.9823 (4.9671)\tPrec@1 20.000 (1.820)\tPrec@5 20.000 (8.301)\n",
            "Epoch: [3][1500/2000]\tTime 1.730 (1.737)\tData 1.191 (1.198)\tLoss 4.9422 (4.9696)\tPrec@1 0.000 (1.825)\tPrec@5 10.000 (8.248)\n",
            "Epoch: [3][1600/2000]\tTime 1.684 (1.736)\tData 1.145 (1.197)\tLoss 4.9267 (4.9709)\tPrec@1 0.000 (1.830)\tPrec@5 0.000 (8.214)\n",
            "Epoch: [3][1700/2000]\tTime 1.715 (1.735)\tData 1.176 (1.196)\tLoss 5.0397 (4.9711)\tPrec@1 0.000 (1.822)\tPrec@5 10.000 (8.277)\n",
            "Epoch: [3][1800/2000]\tTime 1.705 (1.734)\tData 1.165 (1.195)\tLoss 5.0910 (4.9711)\tPrec@1 0.000 (1.882)\tPrec@5 0.000 (8.395)\n",
            "Epoch: [3][1900/2000]\tTime 1.731 (1.733)\tData 1.191 (1.194)\tLoss 5.1255 (4.9686)\tPrec@1 0.000 (1.915)\tPrec@5 10.000 (8.506)\n",
            "Test: [0/100]\tTime 1.191 (1.191)\tLoss 4.9718 (4.9718)\tPrec@1 10.000 (10.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.700 Prec@5 7.300\n",
            " > Validation loss after epoch 3 = 5.023589425086975\n",
            " > Current LR(s) -- [0.008]\n",
            "Epoch: [4][0/2000]\tTime 1.685 (1.685)\tData 1.147 (1.147)\tLoss 4.9935 (4.9935)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            "Epoch: [4][100/2000]\tTime 1.695 (1.715)\tData 1.156 (1.176)\tLoss 5.0975 (4.9498)\tPrec@1 0.000 (1.881)\tPrec@5 0.000 (9.802)\n",
            "Epoch: [4][200/2000]\tTime 1.686 (1.717)\tData 1.148 (1.178)\tLoss 4.7796 (4.9583)\tPrec@1 0.000 (1.940)\tPrec@5 20.000 (9.602)\n",
            "Epoch: [4][300/2000]\tTime 1.730 (1.720)\tData 1.190 (1.181)\tLoss 5.0032 (4.9596)\tPrec@1 10.000 (1.993)\tPrec@5 10.000 (9.203)\n",
            "Epoch: [4][400/2000]\tTime 1.762 (1.720)\tData 1.223 (1.180)\tLoss 4.7639 (4.9601)\tPrec@1 0.000 (1.870)\tPrec@5 30.000 (8.903)\n",
            "Epoch: [4][500/2000]\tTime 1.719 (1.719)\tData 1.180 (1.180)\tLoss 4.8809 (4.9617)\tPrec@1 0.000 (1.916)\tPrec@5 0.000 (8.902)\n",
            "Epoch: [4][600/2000]\tTime 1.752 (1.719)\tData 1.214 (1.179)\tLoss 4.8351 (4.9612)\tPrec@1 10.000 (1.864)\tPrec@5 30.000 (8.719)\n",
            "Epoch: [4][700/2000]\tTime 1.712 (1.717)\tData 1.173 (1.178)\tLoss 4.6055 (4.9585)\tPrec@1 10.000 (1.854)\tPrec@5 40.000 (8.659)\n",
            "Epoch: [4][800/2000]\tTime 1.731 (1.716)\tData 1.192 (1.177)\tLoss 5.0367 (4.9612)\tPrec@1 0.000 (1.773)\tPrec@5 10.000 (8.452)\n",
            "Epoch: [4][900/2000]\tTime 1.737 (1.717)\tData 1.198 (1.178)\tLoss 4.9532 (4.9611)\tPrec@1 0.000 (1.665)\tPrec@5 10.000 (8.413)\n",
            "Epoch: [4][1000/2000]\tTime 1.756 (1.718)\tData 1.216 (1.179)\tLoss 4.8341 (4.9621)\tPrec@1 0.000 (1.688)\tPrec@5 0.000 (8.442)\n",
            "Epoch: [4][1100/2000]\tTime 1.764 (1.720)\tData 1.224 (1.181)\tLoss 4.7335 (4.9635)\tPrec@1 0.000 (1.717)\tPrec@5 20.000 (8.420)\n",
            "Epoch: [4][1200/2000]\tTime 1.756 (1.722)\tData 1.217 (1.183)\tLoss 5.0672 (4.9628)\tPrec@1 0.000 (1.765)\tPrec@5 0.000 (8.376)\n",
            "Epoch: [4][1300/2000]\tTime 1.740 (1.724)\tData 1.200 (1.184)\tLoss 5.0392 (4.9654)\tPrec@1 0.000 (1.768)\tPrec@5 20.000 (8.355)\n",
            "Epoch: [4][1400/2000]\tTime 1.756 (1.724)\tData 1.217 (1.185)\tLoss 4.9800 (4.9661)\tPrec@1 20.000 (1.806)\tPrec@5 20.000 (8.323)\n",
            "Epoch: [4][1500/2000]\tTime 1.760 (1.726)\tData 1.220 (1.187)\tLoss 4.9404 (4.9686)\tPrec@1 0.000 (1.812)\tPrec@5 10.000 (8.281)\n",
            "Epoch: [4][1600/2000]\tTime 1.756 (1.726)\tData 1.217 (1.186)\tLoss 4.9247 (4.9699)\tPrec@1 0.000 (1.818)\tPrec@5 0.000 (8.226)\n",
            "Epoch: [4][1700/2000]\tTime 1.786 (1.726)\tData 1.247 (1.186)\tLoss 5.0392 (4.9701)\tPrec@1 0.000 (1.811)\tPrec@5 10.000 (8.289)\n",
            "Epoch: [4][1800/2000]\tTime 1.759 (1.726)\tData 1.219 (1.187)\tLoss 5.0882 (4.9702)\tPrec@1 0.000 (1.871)\tPrec@5 0.000 (8.406)\n",
            "Epoch: [4][1900/2000]\tTime 1.792 (1.727)\tData 1.252 (1.188)\tLoss 5.1256 (4.9677)\tPrec@1 0.000 (1.904)\tPrec@5 10.000 (8.517)\n",
            "Test: [0/100]\tTime 1.198 (1.198)\tLoss 4.9709 (4.9709)\tPrec@1 10.000 (10.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.700 Prec@5 7.300\n",
            "Epoch     4: reducing learning rate of group 0 to 4.0000e-03.\n",
            " > Validation loss after epoch 4 = 5.023968281745911\n",
            " > Current LR(s) -- [0.004]\n",
            "Epoch: [5][0/2000]\tTime 1.731 (1.731)\tData 1.192 (1.192)\tLoss 4.9920 (4.9920)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            "Epoch: [5][100/2000]\tTime 1.718 (1.721)\tData 1.179 (1.181)\tLoss 5.0876 (4.9482)\tPrec@1 0.000 (1.683)\tPrec@5 0.000 (10.099)\n",
            "Epoch: [5][200/2000]\tTime 1.676 (1.714)\tData 1.136 (1.175)\tLoss 4.7772 (4.9568)\tPrec@1 0.000 (1.741)\tPrec@5 20.000 (9.751)\n",
            "Epoch: [5][300/2000]\tTime 1.757 (1.732)\tData 1.218 (1.192)\tLoss 5.0051 (4.9583)\tPrec@1 10.000 (1.860)\tPrec@5 10.000 (9.302)\n",
            "Epoch: [5][400/2000]\tTime 1.681 (1.732)\tData 1.142 (1.193)\tLoss 4.7341 (4.9584)\tPrec@1 0.000 (1.721)\tPrec@5 30.000 (8.928)\n",
            "Epoch: [5][500/2000]\tTime 1.741 (1.735)\tData 1.201 (1.196)\tLoss 4.8669 (4.9601)\tPrec@1 0.000 (1.776)\tPrec@5 0.000 (8.822)\n",
            "Epoch: [5][600/2000]\tTime 1.753 (1.735)\tData 1.214 (1.196)\tLoss 4.8404 (4.9590)\tPrec@1 10.000 (1.747)\tPrec@5 20.000 (8.702)\n",
            "Epoch: [5][700/2000]\tTime 1.722 (1.738)\tData 1.182 (1.199)\tLoss 4.6119 (4.9559)\tPrec@1 10.000 (1.755)\tPrec@5 40.000 (8.716)\n",
            "Epoch: [5][800/2000]\tTime 1.770 (1.741)\tData 1.230 (1.202)\tLoss 5.0370 (4.9584)\tPrec@1 0.000 (1.748)\tPrec@5 10.000 (8.514)\n",
            "Epoch: [5][900/2000]\tTime 1.759 (1.743)\tData 1.220 (1.204)\tLoss 4.9500 (4.9585)\tPrec@1 0.000 (1.720)\tPrec@5 0.000 (8.280)\n",
            "Epoch: [5][1000/2000]\tTime 1.749 (1.744)\tData 1.209 (1.205)\tLoss 4.8420 (4.9594)\tPrec@1 0.000 (1.778)\tPrec@5 10.000 (8.342)\n",
            "Epoch: [5][1100/2000]\tTime 1.736 (1.744)\tData 1.198 (1.205)\tLoss 4.7259 (4.9604)\tPrec@1 0.000 (1.798)\tPrec@5 20.000 (8.374)\n",
            "Epoch: [5][1200/2000]\tTime 1.813 (1.745)\tData 1.274 (1.206)\tLoss 5.0312 (4.9597)\tPrec@1 0.000 (1.840)\tPrec@5 0.000 (8.335)\n",
            "Epoch: [5][1300/2000]\tTime 1.723 (1.745)\tData 1.183 (1.206)\tLoss 5.0477 (4.9622)\tPrec@1 0.000 (1.837)\tPrec@5 0.000 (8.309)\n",
            "Epoch: [5][1400/2000]\tTime 1.767 (1.746)\tData 1.228 (1.206)\tLoss 4.9668 (4.9629)\tPrec@1 20.000 (1.870)\tPrec@5 20.000 (8.273)\n",
            "Epoch: [5][1500/2000]\tTime 1.752 (1.747)\tData 1.213 (1.207)\tLoss 4.9246 (4.9653)\tPrec@1 0.000 (1.872)\tPrec@5 10.000 (8.241)\n",
            "Epoch: [5][1600/2000]\tTime 1.816 (1.747)\tData 1.276 (1.208)\tLoss 4.9175 (4.9664)\tPrec@1 0.000 (1.874)\tPrec@5 0.000 (8.226)\n",
            "Epoch: [5][1700/2000]\tTime 1.723 (1.747)\tData 1.184 (1.208)\tLoss 5.0424 (4.9666)\tPrec@1 0.000 (1.864)\tPrec@5 10.000 (8.277)\n",
            "Epoch: [5][1800/2000]\tTime 1.740 (1.747)\tData 1.201 (1.208)\tLoss 5.0713 (4.9665)\tPrec@1 0.000 (1.921)\tPrec@5 0.000 (8.379)\n",
            "Epoch: [5][1900/2000]\tTime 1.788 (1.747)\tData 1.249 (1.207)\tLoss 5.1191 (4.9641)\tPrec@1 0.000 (1.952)\tPrec@5 10.000 (8.522)\n",
            "Test: [0/100]\tTime 1.279 (1.279)\tLoss 4.9768 (4.9768)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            " > Validation loss after epoch 5 = 5.025704174041748\n",
            " > Current LR(s) -- [0.004]\n",
            "Epoch: [6][0/2000]\tTime 1.762 (1.762)\tData 1.223 (1.223)\tLoss 4.9760 (4.9760)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [6][100/2000]\tTime 1.783 (1.759)\tData 1.243 (1.220)\tLoss 5.0920 (4.9454)\tPrec@1 0.000 (1.881)\tPrec@5 0.000 (9.802)\n",
            "Epoch: [6][200/2000]\tTime 1.753 (1.752)\tData 1.214 (1.212)\tLoss 4.7746 (4.9539)\tPrec@1 0.000 (1.841)\tPrec@5 20.000 (9.602)\n",
            "Epoch: [6][300/2000]\tTime 1.752 (1.753)\tData 1.213 (1.214)\tLoss 5.0125 (4.9554)\tPrec@1 10.000 (1.927)\tPrec@5 10.000 (9.203)\n",
            "Epoch: [6][400/2000]\tTime 1.765 (1.755)\tData 1.226 (1.215)\tLoss 4.7389 (4.9558)\tPrec@1 0.000 (1.845)\tPrec@5 30.000 (8.853)\n",
            "Epoch: [6][500/2000]\tTime 1.762 (1.759)\tData 1.222 (1.220)\tLoss 4.8696 (4.9575)\tPrec@1 0.000 (1.856)\tPrec@5 0.000 (8.822)\n",
            "Epoch: [6][600/2000]\tTime 1.731 (1.759)\tData 1.193 (1.220)\tLoss 4.8389 (4.9567)\tPrec@1 10.000 (1.830)\tPrec@5 20.000 (8.602)\n",
            "Epoch: [6][700/2000]\tTime 1.786 (1.759)\tData 1.247 (1.220)\tLoss 4.6116 (4.9538)\tPrec@1 10.000 (1.826)\tPrec@5 40.000 (8.631)\n",
            "Epoch: [6][800/2000]\tTime 1.718 (1.761)\tData 1.178 (1.221)\tLoss 5.0314 (4.9565)\tPrec@1 0.000 (1.810)\tPrec@5 10.000 (8.452)\n",
            "Epoch: [6][900/2000]\tTime 1.723 (1.761)\tData 1.184 (1.222)\tLoss 4.9463 (4.9566)\tPrec@1 0.000 (1.776)\tPrec@5 0.000 (8.213)\n",
            "Epoch: [6][1000/2000]\tTime 1.738 (1.760)\tData 1.199 (1.221)\tLoss 4.8407 (4.9577)\tPrec@1 0.000 (1.828)\tPrec@5 10.000 (8.272)\n",
            "Epoch: [6][1100/2000]\tTime 1.713 (1.758)\tData 1.175 (1.219)\tLoss 4.7283 (4.9588)\tPrec@1 0.000 (1.844)\tPrec@5 20.000 (8.311)\n",
            "Epoch: [6][1200/2000]\tTime 1.756 (1.757)\tData 1.217 (1.217)\tLoss 5.0318 (4.9583)\tPrec@1 0.000 (1.882)\tPrec@5 0.000 (8.276)\n",
            "Epoch: [6][1300/2000]\tTime 1.713 (1.755)\tData 1.173 (1.215)\tLoss 5.0451 (4.9609)\tPrec@1 0.000 (1.875)\tPrec@5 0.000 (8.255)\n",
            "Epoch: [6][1400/2000]\tTime 1.777 (1.754)\tData 1.238 (1.214)\tLoss 4.9666 (4.9617)\tPrec@1 20.000 (1.906)\tPrec@5 20.000 (8.230)\n",
            "Epoch: [6][1500/2000]\tTime 1.797 (1.753)\tData 1.258 (1.214)\tLoss 4.9245 (4.9642)\tPrec@1 0.000 (1.905)\tPrec@5 10.000 (8.201)\n",
            "Epoch: [6][1600/2000]\tTime 1.703 (1.751)\tData 1.163 (1.212)\tLoss 4.9164 (4.9653)\tPrec@1 0.000 (1.905)\tPrec@5 0.000 (8.182)\n",
            "Epoch: [6][1700/2000]\tTime 1.684 (1.748)\tData 1.145 (1.209)\tLoss 5.0410 (4.9656)\tPrec@1 0.000 (1.893)\tPrec@5 10.000 (8.230)\n",
            "Epoch: [6][1800/2000]\tTime 1.687 (1.745)\tData 1.148 (1.205)\tLoss 5.0706 (4.9656)\tPrec@1 0.000 (1.949)\tPrec@5 0.000 (8.340)\n",
            "Epoch: [6][1900/2000]\tTime 1.670 (1.742)\tData 1.131 (1.203)\tLoss 5.1219 (4.9633)\tPrec@1 0.000 (1.978)\tPrec@5 10.000 (8.485)\n",
            "Test: [0/100]\tTime 1.183 (1.183)\tLoss 4.9761 (4.9761)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            " > Validation loss after epoch 6 = 5.025525178909302\n",
            " > Current LR(s) -- [0.004]\n",
            "Epoch: [7][0/2000]\tTime 1.705 (1.705)\tData 1.166 (1.166)\tLoss 4.9753 (4.9753)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [7][100/2000]\tTime 1.633 (1.664)\tData 1.094 (1.125)\tLoss 5.0926 (4.9449)\tPrec@1 0.000 (1.881)\tPrec@5 0.000 (9.703)\n",
            "Epoch: [7][200/2000]\tTime 1.659 (1.664)\tData 1.120 (1.125)\tLoss 4.7728 (4.9532)\tPrec@1 0.000 (1.741)\tPrec@5 20.000 (9.552)\n",
            "Epoch: [7][300/2000]\tTime 1.655 (1.665)\tData 1.116 (1.126)\tLoss 5.0134 (4.9548)\tPrec@1 10.000 (1.860)\tPrec@5 10.000 (9.169)\n",
            "Epoch: [7][400/2000]\tTime 1.646 (1.665)\tData 1.108 (1.126)\tLoss 4.7385 (4.9553)\tPrec@1 0.000 (1.796)\tPrec@5 30.000 (8.828)\n",
            "Epoch: [7][500/2000]\tTime 1.661 (1.665)\tData 1.122 (1.126)\tLoss 4.8703 (4.9570)\tPrec@1 0.000 (1.816)\tPrec@5 0.000 (8.802)\n",
            "Epoch: [7][600/2000]\tTime 1.714 (1.666)\tData 1.175 (1.127)\tLoss 4.8403 (4.9563)\tPrec@1 10.000 (1.797)\tPrec@5 20.000 (8.586)\n",
            "Epoch: [7][700/2000]\tTime 1.631 (1.667)\tData 1.091 (1.128)\tLoss 4.6116 (4.9534)\tPrec@1 10.000 (1.797)\tPrec@5 40.000 (8.616)\n",
            "Epoch: [7][800/2000]\tTime 1.651 (1.667)\tData 1.112 (1.128)\tLoss 5.0297 (4.9561)\tPrec@1 0.000 (1.785)\tPrec@5 10.000 (8.439)\n",
            "Epoch: [7][900/2000]\tTime 1.700 (1.667)\tData 1.161 (1.128)\tLoss 4.9461 (4.9563)\tPrec@1 0.000 (1.754)\tPrec@5 0.000 (8.246)\n",
            "Epoch: [7][1000/2000]\tTime 1.671 (1.668)\tData 1.132 (1.129)\tLoss 4.8408 (4.9573)\tPrec@1 0.000 (1.808)\tPrec@5 10.000 (8.302)\n",
            "Epoch: [7][1100/2000]\tTime 1.672 (1.669)\tData 1.132 (1.130)\tLoss 4.7286 (4.9585)\tPrec@1 0.000 (1.826)\tPrec@5 20.000 (8.338)\n",
            "Epoch: [7][1200/2000]\tTime 1.686 (1.670)\tData 1.146 (1.131)\tLoss 5.0316 (4.9580)\tPrec@1 0.000 (1.865)\tPrec@5 0.000 (8.301)\n",
            "Epoch: [7][1300/2000]\tTime 1.675 (1.670)\tData 1.135 (1.131)\tLoss 5.0454 (4.9606)\tPrec@1 0.000 (1.860)\tPrec@5 0.000 (8.263)\n",
            "Epoch: [7][1400/2000]\tTime 1.676 (1.671)\tData 1.136 (1.132)\tLoss 4.9661 (4.9614)\tPrec@1 20.000 (1.892)\tPrec@5 20.000 (8.237)\n",
            "Epoch: [7][1500/2000]\tTime 1.681 (1.672)\tData 1.142 (1.133)\tLoss 4.9245 (4.9639)\tPrec@1 0.000 (1.892)\tPrec@5 10.000 (8.208)\n",
            "Epoch: [7][1600/2000]\tTime 1.685 (1.672)\tData 1.147 (1.133)\tLoss 4.9166 (4.9651)\tPrec@1 0.000 (1.893)\tPrec@5 0.000 (8.195)\n",
            "Epoch: [7][1700/2000]\tTime 1.652 (1.672)\tData 1.113 (1.133)\tLoss 5.0405 (4.9653)\tPrec@1 0.000 (1.881)\tPrec@5 10.000 (8.242)\n",
            "Epoch: [7][1800/2000]\tTime 1.648 (1.672)\tData 1.109 (1.133)\tLoss 5.0702 (4.9654)\tPrec@1 0.000 (1.938)\tPrec@5 0.000 (8.356)\n",
            "Epoch: [7][1900/2000]\tTime 1.666 (1.671)\tData 1.127 (1.132)\tLoss 5.1230 (4.9631)\tPrec@1 0.000 (1.967)\tPrec@5 10.000 (8.501)\n",
            "Test: [0/100]\tTime 1.209 (1.209)\tLoss 4.9758 (4.9758)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            "Epoch     7: reducing learning rate of group 0 to 2.0000e-03.\n",
            " > Validation loss after epoch 7 = 5.025503854751587\n",
            " > Current LR(s) -- [0.002]\n",
            "Epoch: [8][0/2000]\tTime 1.681 (1.681)\tData 1.141 (1.141)\tLoss 4.9754 (4.9754)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [8][100/2000]\tTime 1.706 (1.676)\tData 1.166 (1.137)\tLoss 5.0878 (4.9443)\tPrec@1 0.000 (1.881)\tPrec@5 0.000 (9.604)\n",
            "Epoch: [8][200/2000]\tTime 1.717 (1.676)\tData 1.177 (1.136)\tLoss 4.7718 (4.9528)\tPrec@1 0.000 (1.791)\tPrec@5 20.000 (9.502)\n",
            "Epoch: [8][300/2000]\tTime 1.678 (1.674)\tData 1.139 (1.135)\tLoss 5.0156 (4.9545)\tPrec@1 0.000 (1.860)\tPrec@5 10.000 (9.136)\n",
            "Epoch: [8][400/2000]\tTime 1.626 (1.672)\tData 1.086 (1.133)\tLoss 4.7249 (4.9547)\tPrec@1 0.000 (1.895)\tPrec@5 30.000 (8.803)\n",
            "Epoch: [8][500/2000]\tTime 1.681 (1.676)\tData 1.141 (1.136)\tLoss 4.8629 (4.9564)\tPrec@1 0.000 (1.916)\tPrec@5 0.000 (8.723)\n",
            "Epoch: [8][600/2000]\tTime 1.688 (1.679)\tData 1.147 (1.140)\tLoss 4.8489 (4.9555)\tPrec@1 10.000 (1.913)\tPrec@5 20.000 (8.652)\n",
            "Epoch: [8][700/2000]\tTime 1.660 (1.680)\tData 1.119 (1.141)\tLoss 4.6219 (4.9524)\tPrec@1 10.000 (1.897)\tPrec@5 40.000 (8.673)\n",
            "Epoch: [8][800/2000]\tTime 1.667 (1.681)\tData 1.125 (1.141)\tLoss 5.0205 (4.9549)\tPrec@1 0.000 (1.873)\tPrec@5 10.000 (8.489)\n",
            "Epoch: [8][900/2000]\tTime 1.698 (1.682)\tData 1.157 (1.142)\tLoss 4.9541 (4.9553)\tPrec@1 0.000 (1.831)\tPrec@5 0.000 (8.335)\n",
            "Epoch: [8][1000/2000]\tTime 1.676 (1.683)\tData 1.135 (1.143)\tLoss 4.8517 (4.9562)\tPrec@1 0.000 (1.878)\tPrec@5 10.000 (8.422)\n",
            "Epoch: [8][1100/2000]\tTime 1.694 (1.683)\tData 1.153 (1.143)\tLoss 4.7207 (4.9572)\tPrec@1 0.000 (1.889)\tPrec@5 20.000 (8.483)\n",
            "Epoch: [8][1200/2000]\tTime 1.703 (1.683)\tData 1.160 (1.143)\tLoss 5.0217 (4.9566)\tPrec@1 0.000 (1.923)\tPrec@5 0.000 (8.435)\n",
            "Epoch: [8][1300/2000]\tTime 1.625 (1.683)\tData 1.084 (1.143)\tLoss 5.0520 (4.9591)\tPrec@1 0.000 (1.914)\tPrec@5 0.000 (8.440)\n",
            "Epoch: [8][1400/2000]\tTime 1.737 (1.684)\tData 1.197 (1.144)\tLoss 4.9578 (4.9599)\tPrec@1 20.000 (1.941)\tPrec@5 20.000 (8.430)\n",
            "Epoch: [8][1500/2000]\tTime 1.666 (1.687)\tData 1.126 (1.146)\tLoss 4.9166 (4.9623)\tPrec@1 0.000 (1.939)\tPrec@5 10.000 (8.394)\n",
            "Epoch: [8][1600/2000]\tTime 1.659 (1.684)\tData 1.119 (1.144)\tLoss 4.9186 (4.9633)\tPrec@1 0.000 (1.936)\tPrec@5 0.000 (8.395)\n",
            "Epoch: [8][1700/2000]\tTime 1.640 (1.682)\tData 1.100 (1.142)\tLoss 5.0420 (4.9635)\tPrec@1 0.000 (1.922)\tPrec@5 10.000 (8.442)\n",
            "Epoch: [8][1800/2000]\tTime 1.668 (1.682)\tData 1.129 (1.141)\tLoss 5.0609 (4.9635)\tPrec@1 0.000 (1.977)\tPrec@5 0.000 (8.562)\n",
            "Epoch: [8][1900/2000]\tTime 1.724 (1.682)\tData 1.182 (1.141)\tLoss 5.1207 (4.9612)\tPrec@1 0.000 (2.004)\tPrec@5 10.000 (8.695)\n",
            "Test: [0/100]\tTime 1.262 (1.262)\tLoss 4.9813 (4.9813)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            " > Validation loss after epoch 8 = 5.02503933429718\n",
            " > Current LR(s) -- [0.002]\n",
            "Epoch: [9][0/2000]\tTime 1.694 (1.694)\tData 1.151 (1.151)\tLoss 4.9701 (4.9701)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [9][100/2000]\tTime 1.717 (1.688)\tData 1.176 (1.147)\tLoss 5.0880 (4.9434)\tPrec@1 0.000 (1.881)\tPrec@5 0.000 (9.307)\n",
            "Epoch: [9][200/2000]\tTime 1.681 (1.693)\tData 1.139 (1.152)\tLoss 4.7729 (4.9515)\tPrec@1 0.000 (1.791)\tPrec@5 20.000 (9.353)\n",
            "Epoch: [9][300/2000]\tTime 1.716 (1.691)\tData 1.174 (1.149)\tLoss 5.0191 (4.9532)\tPrec@1 0.000 (1.860)\tPrec@5 10.000 (9.037)\n",
            "Epoch: [9][400/2000]\tTime 1.698 (1.695)\tData 1.158 (1.154)\tLoss 4.7308 (4.9534)\tPrec@1 0.000 (1.895)\tPrec@5 30.000 (8.728)\n",
            "Epoch: [9][500/2000]\tTime 1.736 (1.701)\tData 1.194 (1.160)\tLoss 4.8627 (4.9551)\tPrec@1 0.000 (1.916)\tPrec@5 0.000 (8.663)\n",
            "Epoch: [9][600/2000]\tTime 1.719 (1.704)\tData 1.178 (1.162)\tLoss 4.8459 (4.9543)\tPrec@1 10.000 (1.913)\tPrec@5 20.000 (8.536)\n",
            "Epoch: [9][700/2000]\tTime 1.775 (1.713)\tData 1.235 (1.171)\tLoss 4.6208 (4.9513)\tPrec@1 10.000 (1.897)\tPrec@5 40.000 (8.573)\n",
            "Epoch: [9][800/2000]\tTime 1.719 (1.715)\tData 1.178 (1.174)\tLoss 5.0202 (4.9539)\tPrec@1 0.000 (1.873)\tPrec@5 10.000 (8.402)\n",
            "Epoch: [9][900/2000]\tTime 1.621 (1.711)\tData 1.082 (1.170)\tLoss 4.9486 (4.9543)\tPrec@1 0.000 (1.831)\tPrec@5 0.000 (8.213)\n",
            "Epoch: [9][1000/2000]\tTime 1.665 (1.708)\tData 1.125 (1.167)\tLoss 4.8498 (4.9553)\tPrec@1 0.000 (1.878)\tPrec@5 10.000 (8.312)\n",
            "Epoch: [9][1100/2000]\tTime 1.751 (1.706)\tData 1.211 (1.165)\tLoss 4.7224 (4.9564)\tPrec@1 0.000 (1.889)\tPrec@5 20.000 (8.383)\n",
            "Epoch: [9][1200/2000]\tTime 1.700 (1.703)\tData 1.161 (1.162)\tLoss 5.0207 (4.9558)\tPrec@1 0.000 (1.923)\tPrec@5 0.000 (8.343)\n",
            "Epoch: [9][1300/2000]\tTime 1.619 (1.700)\tData 1.080 (1.159)\tLoss 5.0493 (4.9584)\tPrec@1 0.000 (1.914)\tPrec@5 0.000 (8.355)\n",
            "Epoch: [9][1400/2000]\tTime 1.691 (1.699)\tData 1.151 (1.158)\tLoss 4.9584 (4.9593)\tPrec@1 20.000 (1.941)\tPrec@5 20.000 (8.351)\n",
            "Epoch: [9][1500/2000]\tTime 1.692 (1.697)\tData 1.152 (1.156)\tLoss 4.9163 (4.9618)\tPrec@1 0.000 (1.939)\tPrec@5 10.000 (8.321)\n",
            "Epoch: [9][1600/2000]\tTime 1.670 (1.695)\tData 1.131 (1.154)\tLoss 4.9158 (4.9628)\tPrec@1 0.000 (1.936)\tPrec@5 0.000 (8.326)\n",
            "Epoch: [9][1700/2000]\tTime 1.689 (1.695)\tData 1.150 (1.155)\tLoss 5.0420 (4.9631)\tPrec@1 0.000 (1.922)\tPrec@5 10.000 (8.377)\n",
            "Epoch: [9][1800/2000]\tTime 1.752 (1.696)\tData 1.211 (1.156)\tLoss 5.0593 (4.9631)\tPrec@1 0.000 (1.977)\tPrec@5 0.000 (8.501)\n",
            "Epoch: [9][1900/2000]\tTime 1.745 (1.699)\tData 1.204 (1.158)\tLoss 5.1223 (4.9609)\tPrec@1 0.000 (2.004)\tPrec@5 10.000 (8.638)\n",
            "Test: [0/100]\tTime 1.209 (1.209)\tLoss 4.9818 (4.9818)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            " > Validation loss after epoch 9 = 5.024822869300842\n",
            " > Current LR(s) -- [0.002]\n",
            "Epoch: [10][0/2000]\tTime 1.707 (1.707)\tData 1.167 (1.167)\tLoss 4.9689 (4.9689)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [10][100/2000]\tTime 1.768 (1.749)\tData 1.228 (1.208)\tLoss 5.0884 (4.9430)\tPrec@1 0.000 (1.881)\tPrec@5 0.000 (9.307)\n",
            "Epoch: [10][200/2000]\tTime 1.715 (1.745)\tData 1.175 (1.205)\tLoss 4.7720 (4.9510)\tPrec@1 0.000 (1.791)\tPrec@5 20.000 (9.353)\n",
            "Epoch: [10][300/2000]\tTime 1.751 (1.744)\tData 1.211 (1.204)\tLoss 5.0198 (4.9527)\tPrec@1 0.000 (1.860)\tPrec@5 10.000 (9.037)\n",
            "Epoch: [10][400/2000]\tTime 1.676 (1.741)\tData 1.136 (1.201)\tLoss 4.7316 (4.9529)\tPrec@1 0.000 (1.895)\tPrec@5 30.000 (8.728)\n",
            "Epoch: [10][500/2000]\tTime 1.696 (1.735)\tData 1.156 (1.194)\tLoss 4.8636 (4.9547)\tPrec@1 0.000 (1.916)\tPrec@5 0.000 (8.663)\n",
            "Epoch: [10][600/2000]\tTime 1.713 (1.727)\tData 1.172 (1.187)\tLoss 4.8457 (4.9539)\tPrec@1 10.000 (1.913)\tPrec@5 20.000 (8.552)\n",
            "Epoch: [10][700/2000]\tTime 1.673 (1.724)\tData 1.132 (1.183)\tLoss 4.6203 (4.9510)\tPrec@1 10.000 (1.897)\tPrec@5 40.000 (8.588)\n",
            "Epoch: [10][800/2000]\tTime 1.711 (1.723)\tData 1.171 (1.182)\tLoss 5.0193 (4.9536)\tPrec@1 0.000 (1.873)\tPrec@5 10.000 (8.414)\n",
            "Epoch: [10][900/2000]\tTime 1.690 (1.720)\tData 1.150 (1.180)\tLoss 4.9475 (4.9540)\tPrec@1 0.000 (1.831)\tPrec@5 0.000 (8.224)\n",
            "Epoch: [10][1000/2000]\tTime 1.681 (1.717)\tData 1.140 (1.177)\tLoss 4.8490 (4.9550)\tPrec@1 0.000 (1.878)\tPrec@5 10.000 (8.322)\n",
            "Epoch: [10][1100/2000]\tTime 1.705 (1.714)\tData 1.165 (1.174)\tLoss 4.7228 (4.9561)\tPrec@1 0.000 (1.889)\tPrec@5 20.000 (8.392)\n",
            "Epoch: [10][1200/2000]\tTime 1.738 (1.713)\tData 1.198 (1.172)\tLoss 5.0204 (4.9556)\tPrec@1 0.000 (1.923)\tPrec@5 0.000 (8.351)\n",
            "Epoch: [10][1300/2000]\tTime 1.724 (1.712)\tData 1.184 (1.171)\tLoss 5.0486 (4.9582)\tPrec@1 0.000 (1.914)\tPrec@5 0.000 (8.363)\n",
            "Epoch: [10][1400/2000]\tTime 1.777 (1.713)\tData 1.237 (1.172)\tLoss 4.9584 (4.9591)\tPrec@1 20.000 (1.941)\tPrec@5 20.000 (8.358)\n",
            "Epoch: [10][1500/2000]\tTime 1.700 (1.714)\tData 1.160 (1.174)\tLoss 4.9160 (4.9616)\tPrec@1 0.000 (1.939)\tPrec@5 10.000 (8.328)\n",
            "Epoch: [10][1600/2000]\tTime 1.715 (1.714)\tData 1.174 (1.173)\tLoss 4.9153 (4.9626)\tPrec@1 0.000 (1.936)\tPrec@5 0.000 (8.332)\n",
            "Epoch: [10][1700/2000]\tTime 1.749 (1.713)\tData 1.209 (1.172)\tLoss 5.0418 (4.9629)\tPrec@1 0.000 (1.922)\tPrec@5 10.000 (8.383)\n",
            "Epoch: [10][1800/2000]\tTime 1.734 (1.713)\tData 1.194 (1.172)\tLoss 5.0588 (4.9630)\tPrec@1 0.000 (1.977)\tPrec@5 0.000 (8.506)\n",
            "Epoch: [10][1900/2000]\tTime 1.712 (1.712)\tData 1.171 (1.172)\tLoss 5.1233 (4.9608)\tPrec@1 0.000 (2.004)\tPrec@5 10.000 (8.643)\n",
            "Test: [0/100]\tTime 1.241 (1.241)\tLoss 4.9816 (4.9816)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            "Epoch    10: reducing learning rate of group 0 to 1.0000e-03.\n",
            " > Validation loss after epoch 10 = 5.024752192497253\n",
            " > Current LR(s) -- [0.001]\n",
            "Epoch: [11][0/2000]\tTime 1.704 (1.704)\tData 1.164 (1.164)\tLoss 4.9687 (4.9687)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [11][100/2000]\tTime 1.698 (1.708)\tData 1.157 (1.167)\tLoss 5.0860 (4.9426)\tPrec@1 0.000 (1.881)\tPrec@5 10.000 (9.307)\n",
            "Epoch: [11][200/2000]\tTime 1.777 (1.713)\tData 1.237 (1.173)\tLoss 4.7717 (4.9506)\tPrec@1 0.000 (1.791)\tPrec@5 20.000 (9.055)\n",
            "Epoch: [11][300/2000]\tTime 1.756 (1.720)\tData 1.215 (1.179)\tLoss 5.0215 (4.9524)\tPrec@1 0.000 (1.860)\tPrec@5 10.000 (8.837)\n",
            "Epoch: [11][400/2000]\tTime 1.660 (1.719)\tData 1.119 (1.179)\tLoss 4.7265 (4.9525)\tPrec@1 0.000 (1.895)\tPrec@5 30.000 (8.579)\n",
            "Epoch: [11][500/2000]\tTime 1.733 (1.718)\tData 1.193 (1.177)\tLoss 4.8598 (4.9542)\tPrec@1 0.000 (1.916)\tPrec@5 0.000 (8.563)\n",
            "Epoch: [11][600/2000]\tTime 1.698 (1.718)\tData 1.158 (1.178)\tLoss 4.8509 (4.9534)\tPrec@1 10.000 (1.913)\tPrec@5 20.000 (8.436)\n",
            "Epoch: [11][700/2000]\tTime 1.702 (1.717)\tData 1.162 (1.176)\tLoss 4.6286 (4.9504)\tPrec@1 10.000 (1.897)\tPrec@5 40.000 (8.488)\n",
            "Epoch: [11][800/2000]\tTime 1.709 (1.714)\tData 1.169 (1.174)\tLoss 5.0117 (4.9529)\tPrec@1 0.000 (1.873)\tPrec@5 10.000 (8.327)\n",
            "Epoch: [11][900/2000]\tTime 1.729 (1.713)\tData 1.189 (1.173)\tLoss 4.9537 (4.9534)\tPrec@1 0.000 (1.831)\tPrec@5 0.000 (8.224)\n",
            "Epoch: [11][1000/2000]\tTime 1.679 (1.711)\tData 1.139 (1.171)\tLoss 4.8570 (4.9544)\tPrec@1 0.000 (1.878)\tPrec@5 10.000 (8.322)\n",
            "Epoch: [11][1100/2000]\tTime 1.714 (1.710)\tData 1.173 (1.169)\tLoss 4.7201 (4.9553)\tPrec@1 0.000 (1.889)\tPrec@5 20.000 (8.392)\n",
            "Epoch: [11][1200/2000]\tTime 1.753 (1.712)\tData 1.213 (1.171)\tLoss 5.0184 (4.9548)\tPrec@1 0.000 (1.923)\tPrec@5 0.000 (8.351)\n",
            "Epoch: [11][1300/2000]\tTime 1.690 (1.711)\tData 1.150 (1.170)\tLoss 5.0533 (4.9574)\tPrec@1 0.000 (1.914)\tPrec@5 0.000 (8.363)\n",
            "Epoch: [11][1400/2000]\tTime 1.680 (1.710)\tData 1.140 (1.169)\tLoss 4.9525 (4.9582)\tPrec@1 20.000 (1.941)\tPrec@5 20.000 (8.358)\n",
            "Epoch: [11][1500/2000]\tTime 1.676 (1.709)\tData 1.135 (1.168)\tLoss 4.9125 (4.9607)\tPrec@1 0.000 (1.939)\tPrec@5 10.000 (8.328)\n",
            "Epoch: [11][1600/2000]\tTime 1.670 (1.708)\tData 1.130 (1.167)\tLoss 4.9192 (4.9616)\tPrec@1 0.000 (1.936)\tPrec@5 0.000 (8.332)\n",
            "Epoch: [11][1700/2000]\tTime 1.708 (1.706)\tData 1.168 (1.165)\tLoss 5.0419 (4.9618)\tPrec@1 0.000 (1.922)\tPrec@5 10.000 (8.383)\n",
            "Epoch: [11][1800/2000]\tTime 1.815 (1.707)\tData 1.274 (1.167)\tLoss 5.0565 (4.9619)\tPrec@1 0.000 (1.977)\tPrec@5 0.000 (8.506)\n",
            "Epoch: [11][1900/2000]\tTime 1.726 (1.710)\tData 1.185 (1.169)\tLoss 5.1233 (4.9596)\tPrec@1 0.000 (2.004)\tPrec@5 10.000 (8.643)\n",
            "Test: [0/100]\tTime 1.232 (1.232)\tLoss 4.9837 (4.9837)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            " > Validation loss after epoch 11 = 5.0244819688797\n",
            " > Current LR(s) -- [0.001]\n",
            "Epoch: [12][0/2000]\tTime 1.822 (1.822)\tData 1.283 (1.283)\tLoss 4.9679 (4.9679)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [12][100/2000]\tTime 1.734 (1.802)\tData 1.193 (1.262)\tLoss 5.0862 (4.9422)\tPrec@1 0.000 (1.881)\tPrec@5 10.000 (9.307)\n",
            "Epoch: [12][200/2000]\tTime 1.810 (1.794)\tData 1.270 (1.254)\tLoss 4.7723 (4.9501)\tPrec@1 0.000 (1.791)\tPrec@5 20.000 (9.055)\n",
            "Epoch: [12][300/2000]\tTime 1.745 (1.788)\tData 1.206 (1.248)\tLoss 5.0229 (4.9518)\tPrec@1 0.000 (1.860)\tPrec@5 10.000 (8.837)\n",
            "Epoch: [12][400/2000]\tTime 1.694 (1.784)\tData 1.154 (1.244)\tLoss 4.7292 (4.9519)\tPrec@1 0.000 (1.895)\tPrec@5 30.000 (8.554)\n",
            "Epoch: [12][500/2000]\tTime 1.820 (1.784)\tData 1.279 (1.244)\tLoss 4.8596 (4.9537)\tPrec@1 0.000 (1.916)\tPrec@5 0.000 (8.543)\n",
            "Epoch: [12][600/2000]\tTime 1.803 (1.783)\tData 1.264 (1.243)\tLoss 4.8496 (4.9529)\tPrec@1 10.000 (1.913)\tPrec@5 20.000 (8.403)\n",
            "Epoch: [12][700/2000]\tTime 1.771 (1.780)\tData 1.232 (1.240)\tLoss 4.6278 (4.9499)\tPrec@1 10.000 (1.897)\tPrec@5 40.000 (8.459)\n",
            "Epoch: [12][800/2000]\tTime 1.791 (1.781)\tData 1.251 (1.242)\tLoss 5.0122 (4.9525)\tPrec@1 0.000 (1.873)\tPrec@5 10.000 (8.302)\n",
            "Epoch: [12][900/2000]\tTime 1.805 (1.783)\tData 1.266 (1.243)\tLoss 4.9508 (4.9530)\tPrec@1 0.000 (1.831)\tPrec@5 0.000 (8.202)\n",
            "Epoch: [12][1000/2000]\tTime 1.778 (1.783)\tData 1.239 (1.243)\tLoss 4.8561 (4.9540)\tPrec@1 0.000 (1.878)\tPrec@5 10.000 (8.302)\n",
            "Epoch: [12][1100/2000]\tTime 1.778 (1.783)\tData 1.239 (1.243)\tLoss 4.7208 (4.9550)\tPrec@1 0.000 (1.889)\tPrec@5 20.000 (8.374)\n",
            "Epoch: [12][1200/2000]\tTime 1.850 (1.784)\tData 1.311 (1.244)\tLoss 5.0175 (4.9545)\tPrec@1 0.000 (1.923)\tPrec@5 0.000 (8.335)\n",
            "Epoch: [12][1300/2000]\tTime 1.790 (1.786)\tData 1.250 (1.246)\tLoss 5.0517 (4.9571)\tPrec@1 0.000 (1.914)\tPrec@5 0.000 (8.347)\n",
            "Epoch: [12][1400/2000]\tTime 1.841 (1.787)\tData 1.301 (1.248)\tLoss 4.9532 (4.9579)\tPrec@1 20.000 (1.941)\tPrec@5 20.000 (8.344)\n",
            "Epoch: [12][1500/2000]\tTime 1.735 (1.787)\tData 1.196 (1.247)\tLoss 4.9121 (4.9605)\tPrec@1 0.000 (1.939)\tPrec@5 10.000 (8.314)\n",
            "Epoch: [12][1600/2000]\tTime 1.821 (1.787)\tData 1.279 (1.247)\tLoss 4.9173 (4.9615)\tPrec@1 0.000 (1.936)\tPrec@5 0.000 (8.320)\n",
            "Epoch: [12][1700/2000]\tTime 1.813 (1.787)\tData 1.273 (1.247)\tLoss 5.0423 (4.9617)\tPrec@1 0.000 (1.922)\tPrec@5 10.000 (8.372)\n",
            "Epoch: [12][1800/2000]\tTime 1.815 (1.788)\tData 1.274 (1.248)\tLoss 5.0552 (4.9618)\tPrec@1 0.000 (1.977)\tPrec@5 0.000 (8.495)\n",
            "Epoch: [12][1900/2000]\tTime 1.816 (1.788)\tData 1.275 (1.248)\tLoss 5.1244 (4.9595)\tPrec@1 0.000 (2.004)\tPrec@5 10.000 (8.632)\n",
            "Test: [0/100]\tTime 1.315 (1.315)\tLoss 4.9844 (4.9844)\tPrec@1 0.000 (0.000)\tPrec@5 10.000 (10.000)\n",
            " * Prec@1 1.300 Prec@5 6.700\n",
            " > Validation loss after epoch 12 = 5.024360022544861\n",
            " > Current LR(s) -- [0.001]\n",
            "Epoch: [13][0/2000]\tTime 1.836 (1.836)\tData 1.296 (1.296)\tLoss 4.9674 (4.9674)\tPrec@1 10.000 (10.000)\tPrec@5 20.000 (20.000)\n",
            "Epoch: [13][100/2000]\tTime 1.771 (1.787)\tData 1.232 (1.246)\tLoss 5.0864 (4.9420)\tPrec@1 0.000 (1.881)\tPrec@5 10.000 (9.307)\n",
            "Epoch: [13][200/2000]\tTime 1.826 (1.783)\tData 1.286 (1.243)\tLoss 4.7720 (4.9498)\tPrec@1 0.000 (1.791)\tPrec@5 20.000 (9.055)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqu_ervs_Pb0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}